\section{VI with HMC}
\label{sec:HMCVI}
As suggested by \textcite{Salimans2014} HMC is a very good MCMC method to be used within MCVI as introduced in section~\ref{sec:MCVI}, because it is very efficient, usually requiring fewer steps than other methods for good convergence. However, some care must be taken in the derivation of the auxiliary lower bound, since now the state of the underlying MCMC chain is not just the variable of interest $z$ but also the auxiliary momentum variable, which we will call $v$ as it is related to velocity. So the complete state is the $2d$-dimensional $s=(z, v)$, corresponding to the state $(q, p)$ in the previous section, and the transition $(z_{t-1}, v_{t-1})$ to $(z_t, v_t)$ is obtained by the Hamiltonian Monte Carlo algorithm as described above. The appropriate potential energy $U(z)$ is derived from the posterior density $p(z|x) \propto p(x, z)$, which is known upto a multiplicative constant from Bayes' Theorem:
\begin{equation} \label{eq:VIwithHMCPotEnergy}
U(z) = -\log(p(x, z))
\end{equation}

Unless stated otherwise, the results below will hold for the more general algorithm with partial momentum update, from which the standard HMC algorithm can be recovered by setting $\alpha = 0$. For notational ease we will write $u_{t-1}$ for the updated momentum, which was referred to as $p^*_{t-1}$ in the previous section.

\label{sec:KinEnergyMayDependOnX}
For the initial state of the chain we sample the position from a parametric approximation $q_0(z_0|x)$ as in Variational Inference and the momentum from the distribution $P_\textrm{kin}(v_0|x)$ corresponding to the chosen kinetic energy. Interestingly, there is no theoretical reason for the kinetic energy to be independent of $x$, which can be exploited to improve the quality of the bound (see section~\ref{sec:MassMatrixChoice} below).

\subsection{Deriving the variational lower bound}

The auxiliary lower bound given in equation~\eqref{eq:MCVIAuxLowerBound} derived for the base case can not be used with HMC, since the transition density $q(z_t|z_{t-1}, x)$ is intractable when using the HMC algorithm. The transition densities $q(s_t|s_{t-1}, x)$, however, are nicely tractable, as will be shown below. To incorporate these the derivation of the auxiliary lower bound must be modified:\begin{equation}
\begin{split}
\log & p(x) \geq \mathcal{L} \\
& \geq \mathcal{L} - \E_{q(z_T|x)} \big[ D_{KL}[q(y | z_T, x) || r(y | z_T, x)] \big] \\
& = \E_{q(y, z_T|x)} \Big[ \log p(x, z_T) - \log q(y, z_T|x) \\
& 	\qquad\qquad\qquad\qquad 							+ \log r(y | z_T, x) \Big] \eqqcolon \mathcal{L}_{\textrm{aux}},
\end{split}
\end{equation}
where $y = (s_0, \dots, s_{T-1}, v_T)$.

Here the density of the forward chain can be decomposed using the Markov property into the tractable transition densities:
$\log q(y, z_T|x) = \log q_0(s_0|x) + \sum_{t=1}^T \log q(s_t|s_{t-1}, x)$, where for the initial state we use the density $q_0(s_0|x) = q_0(z_0|x) \cdot P_\textrm{kin}(v_0|x)$, from which it was also sampled.

For the auxiliary reverse density first note that we can rewrite $r(y | z_T, x) = r(s_0, \ldots, s_{T-1}| s_T, x) \cdot r_{\textrm{final}}(v_T | z_T, x)$ for some distribution $r_{\textrm{final}}(v_T|z_T, x)$, which approximates the final distribution of the velocity $v_T$ given the position $z_T$. By then assuming a Markov structure on the reverse model (as for the base case) we get
$\log r(y | z_T, x) = \log r_{\textrm{final}}(v_T | z_T, x) + \sum_{t=1}^T \log r(s_{t-1}|s_t, t, x)$,
where it is crucial to note that the reverse model $r$ may depend on the time step (as discussed in section~\ref{sec:MCVI}).

With these simplification we can rewrite the lower bound as
\begin{equation} \label{eq:HMCVIAuxLowerBound}
\begin{split}
&\mathcal{L_\textrm{aux}} = \E_{q(s_0, \ldots, s_T|x)} \Big[ \log p(x, z_T) - \log q_0(z_0|x) \\
&\;+ \log r_{\textrm{final}}(v_T | z_T, x) - \log P_\textrm{kin}(v_0|x)  \\ 
&\;+ \sum \limits_{t=1}^T \big( \log r(s_{t-1}|s_t, t, x) - \log q(s_t|s_{t-1}, x) \big) \Big],
\end{split}
\end{equation}
where auxiliary models must be learnt for the reverse transitions, i.e. for the reverse model $r(s_{t-1}|s_t, t, x)$, and for $r_{\textrm{final}}(v_T | z_T, x)$, which predicts the final momentum given the final position. We will refer to this model as the final momentum model. Additionally we can learn the step size $\epsilon$ and the covariance matrix (or mass matrix) $M$ of the kinetic energy used by the HMC algorithm. The number of HMC steps and the number of leapfrog steps per iteration have to be integer and are therefore complicated to learn. For this reason they will be considered as hyper parameters of the algorithm, which are fixed in advance. Optimization of this bound is done as for MCVI (compare section~\ref{sec:MCVI}) by using Monte Carlo estimates of the expectation of the gradient. For future reference let's call the optimization of this lower bound Hamiltonian Monte Carlo Variational Inference (HMCVI).

To evaluate this lower bound we need to compute the transition probabilities $q(s_t|s_{t-1}, x)$ implied by the HMC algorithm. A key observation here is that performing Hamiltonian Dynamics (HD) on the variables with a volume-preserving integrator, such as the leapfrog method, is a bijective and volume-preserving step. Therefore the change of variables between the proposed state $(\tilde{z_t}, \tilde{v_t})$ and the state $(z_{t-1}, u_{t-1})$, from which the HD simulation was started, is bijective and has a Jacobian determinant equal to 1. In the following we will write $HD(s)$ to mean the state obtained by applying HD to the state $s$, so $(\tilde{z}_t, \tilde{v}_t) = HD(z_{t-1}, u_{t-1})$. Similarly $revHD(s)$ will denote the state, which results from running HD backwards in time starting from $s$. Further $\delta[.]$ will be used to signify the Dirac delta function.

\subsection{Transition densities without the acceptance step}
\label{sec:TransitionDensitiesNoAcceptance}
Skipping the acceptance step in the HMC algorithm means that the proposed state is always accepted as the new state, so $(z_t, v_t) = (\tilde{z}_t, \tilde{v}_t)$. In this case the transition densities of the forward model follow directly from the bijectivity and volume-preservation of HD:
\begin{equation} \label{eq:ForwardTransitionNoAcceptance}
\begin{split}
q(s_t|&s_{t-1}, x) = q(z_t, v_t| z_{t-1}, v_{t-1}, x) \\
&= q'(revHD(z_t, v_t)|z_{t-1}, v_{t-1}, x) \\
&= q'(z^*_{t-1}, u_{t-1} |z_{t-1}, v_{t-1}, x) \\
&= q_U(u_{t-1}|v_{t-1}, x) \cdot \delta[{z^*}_{t-1} - z_{t-1}],
\end{split}
\end{equation}
where $(z^*_{t-1}, u_{t-1}) \coloneqq revHD(z_t, v_t)$. With $v_{\textrm{samp}} \coloneqq (u_{t-1} - \alpha \cdot v_{t-1})/{\sqrt{1 - \alpha^2}}$, the momentum drawn from the canonical momentum distribution in this step, we can further simplify
\begin{equation} \label{eq:qUDefinition}
q_U(u_{t-1}|v_{t-1}, x) = P_\textrm{kin}(v_{\textrm{samp}}|x) \cdot (\frac{1}{\sqrt{1 - \alpha^2}})^{d}
\end{equation}

For the reverse model $r(s_{t-1}|s_t, t, x)$ we can also exploit the properties of HD to simplify the model to be learnt (with the same notation):
\begin{equation} \label{eq:ReverseTransitionNoAcceptance}
\begin{split}
r(&s_{t-1}|s_{t}, t, x) = r(z_{t-1}, v_{t-1}| z_t, v_t, t, x) \\
&\;= r'(z_{t-1}, v_{t-1} |z^*_{t-1}, u_{t-1},t , x) \\
&\;= r_V(v_{t-1}|z_{t-1}, u_{t-1}, t, x) \cdot \delta[z^*_{t-1} - z_{t-1}] \\
\end{split}
\end{equation}
So the auxiliary reverse model is fixed except for the distribution $r_V$ of the arrival momentum $v_{t-1}$, with which the position $z_{t-1}$ was reached (see the middle column of fig.~\ref{fig:HMC_Effect_Illustration} for examples of arrival momentum distributions). To model this distribution we may use the position $z_{t-1}$, $x$ and the current time step $t$, as well as the updated momentum $u_{t-1}$, which was used in the step away from this point. If we assume a bias due to the initial state, all of these may contain information about the arrival momentum, so they all should be included for a better fitting model.

For the computation of the lower bound the Dirac $\delta$-functions are problematic because their value is infinite, when their argument equals $0$. However, since a delta function appears both in the forward and in the reverse model (whose log-likelihoods are subtracted from each other), the Dirac functions can be handled: The Dirac function $\delta(x)$ can be approximated by a function with a small but extended support, say of width $\kappa$, where its value is $1/\kappa \cdot \mathbb{I}\big[x \in (x - 0.5 \cdot \kappa, x + 0.5 \cdot \kappa)\big]$, so that the property of the Dirac function of integrating to 1 is preserved. Here $\mathbb{I}[x \in A]$ denotes the indicator function of some set $A$, which equals $1$ if $x \in A$ and $0$ otherwise. Taking the limit of this for $\kappa \rightarrow 0$ returns the Dirac function. By subtracting the logarithms of two Dirac functions their height factor, i.e. $1/\kappa$, cancels, so we can safely take the limit and are left with two indicator functions instead of the two Dirac $\delta$-functions.

When computing the lower bound we only require the transition densities of the points generated by the algorithm and these are generated from the previous points by HD. Therefore for all of these transitions the indicator functions will take the value $1$, so taking the logarithm of these terms does not lead to any problems.

The main drawback of leaving out the acceptance step is that the canonical distribution of the state is no longer preserved by the Markov chain transitions and as a result the chain does no longer converge to the canonical distribution. This means that samples from the converged chain will not follow the target distribution. While this would rule out this version of the HMC algorithm for its usual sampling application, it may still be of use for our improved approximation of the posterior distribution, where it is usually only feasible to perform a very limited number of HMC steps for computational reasons. For this reason loosing the asymptotic convergence is acceptable, since the new invariant distribution should differ only slightly from the target distribution and this difference should have little effect on the start of the chain. Apart from the computational simplifications leaving out the acceptance step also makes the algorithm less wasteful, since no proposals are thrown away.

\subsection{Transition densities with the acceptance step}

A drawback of the basic MCVI approach is that when using the latent variable $z$ as the state and proposal density $\tilde{q}(z_t|z_{t-1}, x)$ for new points, then we cannot include the acceptance step of the Metropolis-Hastings algorithm \parencite{Salimans2014}: Letting $\rho(z_{t-1}, z_t)$ be the probability of accepting the transition from $z_{t-1}$ to $z_t$, the transition density is given by $q(z_t|z_{t-1}, x) = \tilde{q}(z_t|z_{t-1}, x) \cdot \rho(z_{t-1}, z_t) + \delta[z_t - z_{t-1}] \cdot P_\textrm{reject}(z_{t-1})$, where $P_\textrm{reject}(z_{t-1}) = \int_{\tilde{z}_{t}} \tilde{q}(\tilde{z}_t|z_{t-1}, x) \cdot (1 - \rho(z_{t-1}, \tilde{z}_t)) d\tilde{z}_t$ is usually intractable. A possible solution would be to explicitly include a binary random variable in the state, which records the acceptance of the previous step. However, this would lead to non-differentiability of the lower bound.

Exploiting the structure of HMC we can bypass this problem and include the acceptance step without introducing any new variables, because in case of rejection the momentum variable is not reset to its previous value, but keeps the updated value (see equation~\eqref{eq:StateAfterAcceptReject} in section~\ref{sec:PartialMomentumUpdate}). In this way it stores the proposed state, which was rejected, making the transition density tractable as shown below.

Crucially by including the acceptance step in the algorithm convergence of the approximation of the posterior to the true posterior is guaranteed, so by performing a sufficient number of HMC steps the obtained approximation can be made to fit arbitrarily well.

\subsubsection{Forward model}

For the derivation of the transition density $q(s_t|s_{t-1}, x)$ let $A$ be the random variable indicating, whether the proposed move was accepted or not, i.e. $A=1$, if the move was accepted, and $A=0$ otherwise. For extra clarity we will in the following write out the probability density functions (denoted by $f$) with the variables explicitly given in the subscript, so for example $q(s_t|s_{t-1}, x) = f_{S_t|S_{t-1}, X}(s_t|s_{t-1}, x)$. Then using the law of total probability we can decompose this as follows:
\begin{equation}
\begin{split}
&f_{S_t|S_{t-1}, X}(s_t|s_{t-1}, x)\\
&\;=\sum_{a=0}^1 \int f_{S_t, A, U_{t-1}|S_{t-1}, X}(s_t, a, u|s_{t-1}, x) du \\
&\;=\sum_{a=0}^1 \int f_{S_t|A, U_{t-1}, S_{t-1}, X}(s_t| a, u, s_{t-1}, x) \\
&\qquad\qquad\cdot \mathbb{P}(A = a|U_{t-1} = u, S_{t-1} = s_{t-1}, x) \\
&\qquad\qquad \cdot f_{U_{t-1}|S_{t-1}, X}(u|s_{t-1}, x) du
\end{split}
\end{equation}
Each term in this expression can be computed:
\begin{itemize}
\item $f_{U_{t-1}|S_{t-1}, X}(u|s_{t-1}, x) = q_U(u|v_{t-1}, x)$ as in equation~\eqref{eq:qUDefinition} for the forward transition without the acceptance step.
\item $\mathbb{P}(A=1|S_{t-1} = s_{t-1}, U_{t-1} = u, x) = p_{\textrm{accept}}(z_{t-1}, u)$ as in equation~\eqref{eq:AcceptanceProbability} and correspondingly $\mathbb{P}(A=0|S_{t-1} = s_{t-1}, U_{t-1} = u, x) = 1- p_{\textrm{accept}}(z_{t-1}, u)$.
\item If the updated state $S^*_{t-1} = (Z_{t-1}, U_{t-1})$ and $A$ are known, the new state can be deduced, so $f_{S_t|A, U_{t-1}, S_{t-1}, X} = f_{S_t|A, S^*_{t-1}}$ with $f_{S_t|A, S^*_{t-1}}(s_t| 1, (z_{t-1}, u)) = \delta \left[s_t - HD(z_{t-1}, u) \right]$ and $f_{S_t|A, S^*_{t-1}}(s_t| 0, (z_{t-1}, u)) = \delta \left[s_t - (z_{t-1}, -u) \right]$.
\end{itemize}

Putting all of these together and integrating out the delta functions gives
\begin{equation}
\begin{split}
q(s_t& |s_{t-1}, x) \\
&= \delta \left[z_{\textrm{revHD}} - z_{t-1} \right] \cdot p_{\textrm{accept}}(z_{t-1}, v_{revHD}) \\
&\qquad\qquad\qquad \cdot q_U(v_{revHD}|v_{t-1}, x) \\
&\quad + \delta \left[ z_t - z_{t-1} \right] \cdot (1 - p_{\textrm{accept}}(z_{t-1}, -v_t)) \\
&\qquad\qquad\qquad \cdot q_U(-v_t|v_{t-1}, x)
\end{split}
\end{equation}
where we write $z_{\textrm{revHD}}$ and $v_{\textrm{revHD}}$ for the projections of $revHD(z_t, v_t)$ into $z$- and $v$-space respectively.

As we will see below, the reverse model densities will also contain a $d$-dimensional Dirac $\delta$-function in each summand, so we can apply the trick introduced in section~\ref{sec:TransitionDensitiesNoAcceptance} to replace $\delta$-functions by indicator functions. Here the indicator functions can be taken to indicate, whether the proposed state was accepted (in the first summand) and rejected (in the second), because the probability of exactly achieving the equality inside the $\delta$-function in the other case is negligible, i.e. if the move is accepted $z_t = z_{t-1}$ will not occur in practice. In the following we will write $\mathbb{I}_\textrm{acc}$ for this indicator.

So we can regard each summand as treating one of the acceptance/rejection cases and since in the first summand $u_{t-1} = v_{revHD}$ and in the second summand $u_{t-1} = -v_t$, the term for the velocity in both cases becomes $q_U(u_{t-1}|v_{t-1}, x)$, where $u_{t-1}$ is the updated velocity generated in the algorithm outlined above. Also the $p_\textrm{accept}$ term is always computed from this $u_{t-1}$ and the current position $z_{t-1}$, so the transition density can easily be calculated during the sampling process as
\begin{align}
\begin{split}
&q(s_t|s_{t-1}, x) = q_U(u_{t-1}|v_{t-1}, x) \\
&\;\;\;\cdot \Big( \mathbb{I}_\textrm{acc} \cdot p_{\textrm{accept}} + (1 - \mathbb{I}_\textrm{acc}) \cdot (1- p_{\textrm{accept}}) \Big),
\end{split}
\end{align}
where we can also simplify $q_U(u_{t-1}|v_{t-1}, x)$ as in equation~\eqref{eq:qUDefinition}.

\subsubsection{Reverse Model}
\label{sec:TransDensitiesWithAcceptReverse}
In the lower bound approximation we also need a density approximation for moves backwards through the chain, i.e. for $r(s_{t-1}|s_t, t, x) = f_{S_{t-1}|S_t,T, X}(s_{t-1} | s_t, t, x)$. By again letting $A$ be the event of accepting the move from $S_{t-1}$ to $S_t$ we can apply the law of total probability to simplify the problem:
\begin{equation}
\begin{split}
&f_{S_{t-1}|S_t, T, X}(s_{t-1} | s_t, t, x) \\
&\qquad = \sum_{a} f_{S_{t-1}, A|S_t, T, X}(s_{t-1}, a | s_t, t, x) \\
&\qquad = \sum_{a} f_{S_{t-1} |A, S_t, T, X}(s_{t-1} | a, s_t, t, x) \\
&\qquad\qquad\qquad\qquad \cdot \mathbb{P}(A = a | S_t = s_t, t, x)
\end{split}
\end{equation}
The individual terms are now easier to handle:
\begin{itemize}
\item If we know that the previous move was accepted, we can use the reversibility of HD to obtain the state $S_{t-1}^* = (Z_{t-1}, U_{t-1})$, from which the HD-simulation was started, so
\begin{equation}
\begin{split}
&f_{S_{t-1} |A, S_t, T, X}(s_{t-1} | 1, s_t, t, x) \\
&\quad= f_{S_{t-1} |S_{t-1}^*, T, X}\big(s_{t-1} | revHD(s_t), t, x\big) \\
&\quad= \delta \left[z_{t-1} - z_{\textrm{revHD}} \right] \\
&\quad\qquad \cdot r_V(v_{t-1}|z_{\textrm{revHD}}, v_{\textrm{revHD}}, t, x) \\
&\quad= \mathbb{I}_\textrm{acc} \cdot r_V(v_{t-1}|z_{t-1}, u_{t-1}, t, x) 
\end{split}
\end{equation}
with $r_V$ as in equation~\eqref{eq:ReverseTransitionNoAcceptance} and the updated momentum $u_{t-1} = v_{\textrm{revHD}}$. As described earlier the $\delta$-function is replaced by an indicator function by cancelling it against the $\delta$-function in the forward density.
\item If the previous move was not accepted, we know that the current state equals the state $S_{t-1}^*$ (with the velocity negated) from which the HD-transition was started, but rejected, so
\begin{equation}
\begin{split}
&f_{S_{t-1} |A, S_t, T, X}(s_{t-1} | 0, s_t, t, x) \\
&\quad= f_{S_{t-1} |S_{t-1}^*, T, X}\big(s_{t-1} | (z_t, -v_t), t, x\big) \\
&\quad= \delta \left[z_{t-1} - z_{t} \right] \cdot r_V(v_{t-1}|z_{t-1}, -v_t, t, x) \\
&\quad= (1 - \mathbb{I}_\textrm{acc}) \cdot r_V(v_{t-1}| z_{t-1}, u_{t-1}, t, x)
\end{split}
\end{equation}
where now $u_{t-1} = -v_t$ and the $\delta$-function is again converted to an indicator function by cancellation.

If these densities are computed during the sampling process, $u_{t-1}$ is directly available and does not need to be recomputed.
\item The probability $\mathbb{P}(A = 1|S_t = s_t, t, x)$ of accepting the previous step can be simplified under certain circumstances (for the derivation see appendix~\ref{app:DerivationOfReverseAcceptanceProbability}): If $H(revHD(s_t)) \leq H(s_t)$, then $\mathbb{P}(A = 1|S_t = s_t, t, x) = 1$. Otherwise, this reverse acceptance probability needs to be learnt, but will tend towards $\exp(-H(revHD(s_t)) + H(s_t))$ as the chain converges. 
\item $\mathbb{P}(A = 0|S_t = s_t, t, x) = 1 - \mathbb{P}(A = 1|S_t = s_t, t, x)$
\end{itemize}

To capture the density of the backward Markov chain a full auxiliary reverse model should therefore consist of two parts: Firstly the density estimating model for $r_V(v_{t-1}|z_{t-1}, u_{t-1}, t, x)$ as for the case without the acceptance step and secondly a model for $\mathbb{P}(A = 1|S_t = s_t, t, x)$. Regarding $r_V$ a small difference to the case without the acceptance step is, that here $v_{t-1}$ is not always the end of a previous HD simulation, but can also be equal to  $-u_{t-2}$, the updated momentum at the start of the previous simulation, if the resulting proposal was rejected. 

Putting these terms together the reverse transition density is given by
\begin{equation}
\begin{split}
r(s_{t-1} &| s_t, t, x) = r_V(v_{t-1}| z_{t-1}, u_{t-1}, t, x) \\
&\cdot \Big( \mathbb{I}_\textrm{acc} \cdot \mathbb{P}(A = 1 | s_{t}, t, x) \\
&\qquad\; + (1 - \mathbb{I}_\textrm{acc}) \cdot \mathbb{P}(A = 0 | s_{t}, t, x) \Big)
\end{split}
\end{equation}
With this last component for the computation of the auxiliary lower bound using the full HMC algorithm including the acceptance step we are now able to apply the full HMC algorithm within the MCVI framework. In particular, we recover the guaranteed convergence to the exact posterior, which was lost by skipping the acceptance step.

\subsection{Learning the mass matrix}
\label{sec:MassMatrixChoice}
In its usual application as a sampling algorithm the freedom in the configuration of the HMC is often a curse, since a lot of parameters have to be specified, for example the mass matrix and the step size. These choices may then dramatically change the performance of the algorithm. In our application, however, we can side-step this issue by allowing all continuous parameters of the algorithm to be learnt, in particular the mass matrix $M$. As explained in section~\ref{sec:EffectOfKineticEnergyChoice} choice of mass matrix is equivalent to a rescaling of the "position"-space (here the $z$-space), which may improve the convergence of the algorithm. It is important to keep in mind, that the space is not actually transformed, but that the mass matrix makes the algorithm behave as if the space was transformed.

In addition to this indirect contribution to the lower bound through improved convergence, the mass matrix also directly appears in the lower bound as the covariance matrix of the canonical momentum distribution: From the lower bound and the transition densities derived in the previous sections we see that for each HMC step a term $-\log P_\textrm{kin}(v_\textrm{samp}|x)$ appears. Here $P_\textrm{kin}$ is the density of the canonical momentum distribution, a zero-mean multivariate normal distribution with covariance matrix $M$, and $v_\textrm{samp}$ is a sample from this distribution. In the lower bound the expectation of this term is taken w.r.t.\ the distribution, which generated $v_\textrm{samp}$, i.e. the canonical momentum distribution, so the contribution to the lower bound is
\begin{equation}
\begin{split}
&\E_{P_\textrm{kin}(v|x)} \Big[ -\log P_\textrm{kin}(v|x) \Big] \\
&\quad= \frac{1}{2}\E_{P_\textrm{kin}} \left[d\log(2 \pi) + \log(|M|) +  v^T M^{-1} v \right] \\
&\quad= \frac{1}{2} \Big( d \log(2 \pi) + \log(|M|) + d \Big), 
\end{split}
\end{equation}
since $v^T M^{-1} v$ has a $\chi^2$-distribution on $d$ degrees of freedom, which therefore has expected value $d$. 

%Assuming for simplicity that $M$ is diagonal, this simplifies to
%\begin{equation}
%\begin{split}
%\E_{P_\textrm{kin}(v|x)}& \Big[ -\log P_\textrm{kin}(v|x) \Big] \\
%&= \frac{d}{2} \Big( \log(2 \pi) + 1 \Big) + \frac{1}{2} \sum_{i=1}^d \log(m_i),
%\end{split}
%\end{equation}
%where $m_i$ is the $i^{\textrm{th}}$ diagonal element of $M$.
%
Now in the reverse model we have the density $r_V(v_{t-1}|z_{t-1}, u_{t-1}, t, x)$ capturing the distribution of the arrival momentum. In other words this tries to learn, the momentum distribution at the end of the HD simulations. Thus it should be closely related to the momentum distribution at the start of the HD simulations, which is exactly $P_\textrm{kin}$. Assuming a multivariate normal density for $r_V$, in particular their covariance matrices should be similar, so their direct contributions to the lower bound via forward and reverse densities should offset each other and not have a significant influence on value of $M$.

The straight forward approach for the choice of mass matrix is to learn a single global mass matrix, which is used for all observed variables $x$. This corresponds to a global rescaling of the latent space for all computations within the algorithm. However, the potential energy $U(z)$ defining the landscape, on which the dynamics are simulated, may strongly depend on $x$ (see equation~\eqref{eq:VIwithHMCPotEnergy}) and require a different rescaling for each $x$ for optimal performance. Therefore a global rescaling will probably only have limited effect on the lower bound.

The obvious consequence of these considerations is to make the mass matrix dependent on $x$, which from a physical point of view corresponds to the masses of the simulated particles differing for different observed variables $x$. This extension, which does not violate any theoretical considerations (see section~\ref{sec:KinEnergyMayDependOnX}), allows the optimal rescaling for each data point to be learnt and should greatly enhance the performance of the algorithm.

\subsection{Computational Simplifications}

So far we have presented the theory behind HMCVI aiming for mathematical completeness and clarity, but when it comes to actually performing these computations some simplifications can be made.

\subsubsection{Simplifications for HMCVI without Partial Momentum Update}
\label{sec:SimplificationWithoutPartialMomentumUpdate}
If we do not perform partial momentum updates, then the initial momentum $v_0$ is immediately replaced in the first step of the HMC algorithm. Thus it should not influence the lower bound at all. The reason is that, if $\alpha = 0$, then $r(v_0|z_0, u_0, t=1, x) = P_\textrm{kin}(v_0|x)$ is the optimal choice, since $z_0$ and $u_0$ contain no information about $v_0$. These terms appear with opposite sign in the loss, so by simply cancelling them instead of learning their equality we can save some computation time.

Furthermore without partial momentum updates the updated momentum $u_t$ is sampled fresh from the canonical momentum distribution, so it does not contain any information about the previous momentum $v_t$. Therefore $u_t$ should not be used as an input in all the reverse models. Conveniently in this case the density predicting the arrival momentum $r_V$ has the same inputs as the final momentum model $r_\textrm{final}$, so we can combine them by setting $r_\textrm{final}(v_T | z_T, x) = r_V(v_T | z_T, T+1, x)$.

\subsubsection{Computing Expectations Explicitly}

The lower bound $\mathcal{L_\textrm{aux}}$ is given as the expectation of a sum of terms in equation~\eqref{eq:HMCVIAuxLowerBound}, but for some of these terms the expectation can be computed explicitly reducing the noise in the stochastic gradient estimates used for training. In particular, the forward model density terms can usually be solved analytically. The reason is that the expectation over the sampled path is actually the expectation over all the random variables determining this path, namely the initial state sampled from $q_0$ and the various momentum updates all sampled the canonical momentum distribution $P_\textrm{kin}$. The forward model terms just consist of the negative logarithms of these densities (and some additional indicator functions) and the expectation of the negative log-likelihood of a random variable is actually its entropy, which has a closed form for most distributions.
