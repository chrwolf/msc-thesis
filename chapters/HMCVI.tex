\section{VI with HMC}
\label{sec:HMCVI}
As suggested by \textcite{Salimans2014} HMC is a very good MCMC method to be used within MCVI as introduced in section~\ref{sec:MCVI}, because it is very efficient, usually requiring fewer steps than other methods for good convergence. However, some care must be taken in the derivation of the auxiliary lower bound, since now the state of the generated Markov chain is not just the variable of interest $z$, but also the auxiliary momentum variable, which we will call $v$ (as it is related to velocity). The complete state is thus given by the $2d$-dimensional $s=(z, v)$, corresponding to the state $(q, p)$ in the previous section. The appropriate potential energy $U(z)$ is derived from the posterior density $p(z|x) \propto p(x, z)$, which is known upto a multiplicative constant from Bayes' Theorem:
\begin{equation} \label{eq:VIwithHMCPotEnergy}
U(z) = -\log p(x, z).
\end{equation}

Unless stated otherwise, the results below will hold for the more general algorithm with partial momentum updates, from which the standard HMC algorithm can be recovered by setting $\alpha = 0$. For notational ease we will write $u_{t-1}$ for the updated momentum, which was referred to as $p^*_{t-1}$ in the previous section. 

For the initial state of the chain we sample the position from a parametric approximation $q_0(z_0|x)$ and the momentum from the distribution $f_\textrm{kin}(v_0|x)$ corresponding to the chosen kinetic energy, so the density of the initial state is $q_0(s_0|x)=q_0(z_0|x) \cdot f_\textrm{kin}(v_0|x)$. Interestingly, there is no theoretical reason for the kinetic energy to be independent of $x$. This can be exploited to improve the quality of the bound (see section~\ref{sec:MassMatrixChoice} below). \label{sec:KinEnergyMayDependOnX}

\subsection{Deriving the variational lower bound}

The auxiliary lower bound given in equation~\eqref{eq:MCVIAuxLowerBound} can not be used with the HMC algorithm, since there the transition density $q(z_t|z_{t-1}, x)$ is intractable. The transition densities $q(s_t|s_{t-1}, x)$, however, can be easily computed (shown below). To incorporate these, the derivation of the auxiliary lower bound must be modified:\begin{equation}
\begin{split}
\log & p(x) \geq \mathcal{L} \\
& \geq \mathcal{L} - \E_{q(z_T|x)} \big[ D_{KL}[q(y | z_T, x) || r(y | z_T, x)] \big] \\
& = \E_{q(y, z_T|x)} \Big[ \log p(x, z_T) - \log q(y, z_T|x) \\
& 	\qquad\qquad\qquad\qquad 							+ \log r(y | z_T, x) \Big] \eqqcolon \mathcal{L}_{\textrm{aux}},
\end{split}
\end{equation}
where $y = (s_0, \dots, s_{T-1}, v_T)$.

Using the Markov property the density of the forward chain can be decomposed into the tractable transition densities and the density of the initial state: $\log q(y, z_T|x) = \log q_0(s_0|x) + \sum_{t=1}^T \log q(s_t|s_{t-1}, x)$. For the auxiliary reverse density we can rewrite $r(y | z_T, x) = r(s_0, \ldots, s_{T-1}| s_T, x) \cdot r_{\textrm{final}}(v_T | z_T, x)$ for some distribution $r_{\textrm{final}}(v_T|z_T, x)$, which approximates the final distribution of the momentum $v_T$ given the position $z_T$. By then assuming a Markov structure on the reverse model (as for the base case) we get $\log r(y | z_T, x) = \log r_{\textrm{final}}(v_T | z_T, x) + \sum_{t=1}^T \log r(s_{t-1}|s_t, t, x)$, where the reverse model $r$ may depend on the time step (as discussed in section~\ref{sec:MCVI}). With these assumptions we can rewrite the lower bound as
\begin{equation} \label{eq:HMCVIAuxLowerBound}
\begin{split}
&\mathcal{L_\textrm{aux}} = \E_{q(s_0, \ldots, s_T|x)} \Big[ \log p(x, z_T) - \log q_0(z_0|x) \\
&\;+ \log r_{\textrm{final}}(v_T | z_T, x) - \log f_\textrm{kin}(v_0|x)  \\ 
&\;+ \sum \limits_{t=1}^T \big( \log r(s_{t-1}|s_t, t, x) - \log q(s_t|s_{t-1}, x) \big) \Big].
\end{split}
\end{equation}
For this bound auxiliary models must be learnt for the reverse transition model $r(s_{t-1}|s_t, t, x)$ and for $r_{\textrm{final}}(v_T | z_T, x)$, which we will refer to as the final momentum model. Additionally, we can learn the step size $\epsilon$ and the covariance matrix (or mass matrix) $M$ of the kinetic energy used by the HMC algorithm. The number of HMC steps and the number of leapfrog steps per iteration have to be integer and are therefore complicated to learn. For this reason, they will be considered as hyperparameters of the algorithm, which are fixed in advance. Optimization of this bound is done as for MCVI (compare section~\ref{sec:MCVI}) by using Monte Carlo estimates of the expectation of the gradient. For future reference we will call the optimization of this lower bound Hamiltonian Monte Carlo Variational Inference (HMCVI).

To evaluate this lower bound, the transition probabilities $q(s_t|s_{t-1}, x)$ implied by the HMC algorithm must be computed. A key observation here is that performing HD on the variables with a volume-preserving integrator, such as the leapfrog method, is a bijective and volume-preserving mapping. Therefore, the change of variables\footnote{The density after the change of variables will be marked by an apostrophe, since it formally is a different function.} between the proposed state $\tilde{s}_t = (\tilde{z}_t, \tilde{v}_t)$ and the state $s^*_{t-1} = (z_{t-1}, u_{t-1})$ from which the HD simulation was started, is bijective and has a Jacobian determinant equal to 1 (see fig.~\ref{fig:HMC_schematic} for the used naming of intermediate states in the HMC algorithm). In the following, we will write $revHD(s)$ to denote the state which results from running HD backwards in time starting from $s$. Further $\delta[.]$ will be used to signify the Dirac $\delta$-function.

\subsection{Transition densities without the acceptance step}
\label{sec:TransitionDensitiesNoAcceptance}
If we leave out the acceptance step in the HMC algorithm, the proposed state is always accepted as the new state, so $s_t = \tilde{s}_t$. In this case, the transition densities of the forward model follow directly from the bijectivity and volume-preservation of HD:
\begin{equation} \label{eq:ForwardTransitionNoAcceptance}
\begin{split}
q(s_t|&s_{t-1}, x) = q'(revHD(s_t)|s_{t-1}, x) \\
&= q'(z^*_{t-1}, u_{t-1} |z_{t-1}, v_{t-1}, x) \\
&= q_U(u_{t-1}|v_{t-1}, x) \cdot \delta[{z}^*_{t-1} - z_{t-1}],
\end{split}
\end{equation}
where $(z^*_{t-1}, u_{t-1}) \coloneqq revHD(z_t, v_t)$. With $v_{\textrm{samp}} \coloneqq (u_{t-1} - \alpha \cdot v_{t-1})/{\sqrt{1 - \alpha^2}}$, the momentum drawn from the canonical momentum distribution in this step, we can simplify the density of the updated momentum
\begin{equation} \label{eq:qUDefinition}
q_U(u_{t-1}|v_{t-1}, x) = f_\textrm{kin}(v_{\textrm{samp}}|x) \cdot (\frac{1}{\sqrt{1 - \alpha^2}})^{d}.
\end{equation}

For the reverse model $r(s_{t-1}|s_t, t, x)$ we can also exploit the properties of HD to simplify the model to be learnt (with the same notation):
\begin{equation} \label{eq:ReverseTransitionNoAcceptance}
\begin{split}
r(&s_{t-1}|s_{t}, t, x) = r'(z_{t-1}, v_{t-1} |z^*_{t-1}, u_{t-1},t , x) \\
&\;= r_V(v_{t-1}|z_{t-1}, u_{t-1}, t, x) \cdot \delta[z^*_{t-1} - z_{t-1}] \\
\end{split}
\end{equation}
Thus the auxiliary reverse model is fixed except for the density $r_V$ of the \textit{arrival} momentum $v_{t-1}$, with which the position $z_{t-1}$ was reached. As inputs to a model of this distribution we may use the position $z_{t-1}$, $x$, the current time step $t$ and the updated momentum $u_{t-1}$, with which the particle left the position $z_{t-1}$. All of these may contain information about the arrival momentum, so they all should be included for a better fitting model.

For the computation of the lower bound the Dirac $\delta$-functions are problematic, because their value is infinite, when their argument equals $0$. However, since a $\delta$-function appears both in the forward and in the reverse model (whose log-likelihoods are subtracted from each other), the $\delta$-functions can be handled: $\delta(x)$ can be approximated by a function with an extended support of width $\kappa$, where its value is $1/\kappa \cdot \mathbb{I}\big[x \in (x - 0.5 \cdot \kappa, x + 0.5 \cdot \kappa)\big]$. Here, $\mathbb{I}[x \in A]$ denotes the indicator function of some set $A$, which equals $1$, if $x \in A$, and is $0$ otherwise. Like for the $\delta$-function, the integral of this approximation over the real line is 1. Therefore taking the limit of this approximation as $\kappa \rightarrow 0$ gives $\delta(x)$. When subtracting the logarithms of two such approximations, the $1/\kappa$ factors cancel, so we can safely take the limit and are left with two indicator functions instead of the two Dirac $\delta$-functions.

The main drawback of leaving out the acceptance step is that the canonical distribution of the state is no longer preserved by the Markov chain transitions and as a result the chain does no longer converge to the canonical distribution. This means that samples from the converged chain will not follow the target distribution. While this would rule out the algorithm for its usual sampling application, it may still be of use for improving the approximation of the posterior distribution, because here it is usually only feasible to perform a very limited number of HMC steps for computational reasons. Thus loosing the asymptotic convergence is acceptable, since the initial steps of the chain should be similar. Apart from the computational simplifications, leaving out the acceptance step also makes the algorithm less wasteful, since no proposals are discarded.

\subsection{Transition densities with the acceptance step}

When using the latent variable $z$ alone as the state, the transition density $q(z_{t-1}|z_{t-1},x)$ for staying at the same location cannot be computed for the Metropolis-Hastings algorithm: Either the proposed state exactly matched the old state or a now unknown proposed state was rejected. Computing the probability of the second possibility requires the integration of the rejection probability over all possible proposed points, i.e.\ the integral $\int_{z} \tilde{q}(z|z_{t-1}, x) \cdot (1 - p_{\textrm{accept}}(z_{t-1}, z)) dz$, where $\tilde{q}$ is the proposal density and $p_{\textrm{accept}}$ is the acceptance probability defined in equation~\eqref{eq:Metropolis-Hastings}. This is usually intractable. A possible solution would be to explicitly include a binary random variable in the state, which records the acceptance of the previous step. However, this would lead to non-differentiability of the lower bound \parencite{Salimans2014}.

Exploiting the structure of HMC, we can bypass this problem and include the acceptance step without introducing any new variables, because in case of rejection the momentum variable is not reset to its previous value, but keeps the updated value (see equation~\eqref{eq:StateAfterAcceptReject} in section~\ref{sec:PartialMomentumUpdate}). In this way it stores the proposed state, which was rejected. This removes the problematic integral and thus makes the transition density tractable, as we will demonstrate in detail below.

Crucially, by including the acceptance step in the algorithm, convergence of the Markov chain to the true posterior is guaranteed. Hence, an arbitrarily exact approximation to the posterior can be obtained by performing a sufficient number of HMC steps.

\subsubsection{Forward model}

For the derivation of the transition density $q(s_t|s_{t-1}, x)$, let $A$ be the random variable indicating, whether the proposed move was accepted or not, i.e.\ $A=1$, if the move was accepted, and $A=0$ otherwise. For extra clarity, we will in the following write out the probability density functions (denoted by $f$) with the variables explicitly given in the subscript, so for example $q(s_t|s_{t-1}, x) = f_{S_t|S_{t-1}, X}(s_t|s_{t-1}, x)$. Using the law of total probability we can then decompose the transition density as follows:
\begin{equation}
\begin{split}
&f_{S_t|S_{t-1}, X}(s_t|s_{t-1}, x)\\
&\;=\sum_{a=0}^1 \int f_{S_t, A, U_{t-1}|S_{t-1}, X}(s_t, a, u|s_{t-1}, x) du \\
&\;=\sum_{a=0}^1 \int f_{S_t|A, U_{t-1}, S_{t-1}, X}(s_t| a, u, s_{t-1}, x) \\
&\qquad\qquad\cdot \mathbb{P}(A = a|U_{t-1} = u, S_{t-1} = s_{t-1}, x) \\
&\qquad\qquad \cdot f_{U_{t-1}|S_{t-1}, X}(u|s_{t-1}, x) du
\end{split}
\end{equation}
Each term in this expression can be computed:
\begin{itemize}
\item $f_{U_{t-1}|S_{t-1}, X}(u|s_{t-1}, x) = q_U(u|v_{t-1}, x)$ as in equation~\eqref{eq:qUDefinition} for the forward transition without the acceptance step.
\item $\mathbb{P}(A=1|S_{t-1} = s_{t-1}, U_{t-1} = u, x) = p_{\textrm{accept}}(z_{t-1}, u)$ as in equation~\eqref{eq:AcceptanceProbability} and correspondingly $\mathbb{P}(A=0|S_{t-1} = s_{t-1}, U_{t-1} = u, x) = 1- p_{\textrm{accept}}(z_{t-1}, u)$.
\item If the updated state $S^*_{t-1} = (Z_{t-1}, U_{t-1})$ and $A$ are known, the new state is uniquely determined, so $f_{S_t|A, U_{t-1}, S_{t-1}, X} = f_{S_t|A, S^*_{t-1}}$ with $f_{S_t|A, S^*_{t-1}}(s_t| 1, (z_{t-1}, u)) = \delta \left[s_t - HD(z_{t-1}, u) \right]$ and $f_{S_t|A, S^*_{t-1}}(s_t| 0, (z_{t-1}, u)) = \delta \left[s_t - (z_{t-1}, -u) \right]$.
\end{itemize}

Inserting these terms in the above decomposition and integrating out the delta functions gives
\begin{equation}
\begin{split}
q(s_t& |s_{t-1}, x) \\
&= \delta \left[z_{\textrm{revHD}} - z_{t-1} \right] \cdot p_{\textrm{accept}}(z_{t-1}, v_{revHD}) \\
&\qquad\qquad\qquad \cdot q_U(v_{revHD}|v_{t-1}, x) \\
&\quad + \delta \left[ z_t - z_{t-1} \right] \cdot (1 - p_{\textrm{accept}}(z_{t-1}, -v_t)) \\
&\qquad\qquad\qquad \cdot q_U(-v_t|v_{t-1}, x),
\end{split}
\end{equation}
where we write $z_{\textrm{revHD}}$ and $v_{\textrm{revHD}}$ for the projections of $revHD(z_t, v_t)$ into $z$- and $v$-space respectively.

As we will see below, the reverse model densities will also contain a $d$-dimensional Dirac $\delta$-function in each summand, so we can apply the trick introduced in section~\ref{sec:TransitionDensitiesNoAcceptance} to replace $\delta$-functions by indicator functions. Here, the indicator functions can be taken to indicate, whether the proposed state was accepted (in the first summand) or rejected (in the second), because the probability of exactly achieving the equality inside the $\delta$-function in the opposite case is negligible, i.e.\ if the move is accepted, $z_t = z_{t-1}$ will not occur in practice. In the following, we will write $\mathbb{I}_\textrm{acc}$ for this indicator.

Thus, we can regard each summand as treating one of the acceptance/rejection cases. Writing $u_{t-1}$ for the updated momentum generated in the HMC algorithm, we have $u_{t-1} = v_{revHD}$ in the first summand and $u_{t-1} = -v_t$ in the second summand. In other words, the $q_U$ term in both summands is $q_U(u_{t-1}|v_{t-1}, x)$. Also, the $p_\textrm{accept}$ term is always computed from $u_{t-1}$ and the current position $z_{t-1}$, so the transition density can easily be calculated during the sampling process as
\begin{align}
\begin{split}
&q(s_t|s_{t-1}, x) = q_U(u_{t-1}|v_{t-1}, x) \\
&\;\;\;\cdot \Big( \mathbb{I}_\textrm{acc} \cdot p_{\textrm{accept}} + (1 - \mathbb{I}_\textrm{acc}) \cdot (1- p_{\textrm{accept}}) \Big),
\end{split}
\end{align}
where we can also simplify $q_U(u_{t-1}|v_{t-1}, x)$ as in equation~\eqref{eq:qUDefinition}.

\subsubsection{Reverse model}
\label{sec:TransDensitiesWithAcceptReverse}
In the lower bound we also need a density approximation for moves backwards through the chain, i.e.\ for $r(s_{t-1}|s_t, t, x) = f_{S_{t-1}|S_t,T, X}(s_{t-1} | s_t, t, x)$. By again letting $A$ be the event of accepting the proposed transition, we can apply the law of total probability to simplify the problem:
\begin{equation}
\begin{split}
&f_{S_{t-1}|S_t, T, X}(s_{t-1} | s_t, t, x) \\
&\qquad = \sum_{a} f_{S_{t-1}, A|S_t, T, X}(s_{t-1}, a | s_t, t, x) \\
&\qquad = \sum_{a} f_{S_{t-1} |A, S_t, T, X}(s_{t-1} | a, s_t, t, x) \\
&\qquad\qquad\qquad\qquad \cdot \mathbb{P}(A = a | S_t = s_t, t, x)
\end{split}
\end{equation}
The individual terms are now easier to handle:
\begin{itemize}
\item If we know that the previous move was accepted, we can use the reversibility of HD to obtain the state $S_{t-1}^* = (Z_{t-1}, U_{t-1})$, from which the HD-simulation was started, so
\begin{equation}
\begin{split}
&f_{S_{t-1} |A, S_t, T, X}(s_{t-1} | 1, s_t, t, x) \\
&\quad= f_{S_{t-1} |S_{t-1}^*, T, X}\big(s_{t-1} | revHD(s_t), t, x\big) \\
&\quad= \delta \left[z_{t-1} - z_{\textrm{revHD}} \right] \\
&\quad\qquad \cdot r_V(v_{t-1}|z_{\textrm{revHD}}, v_{\textrm{revHD}}, t, x) \\
&\quad= \mathbb{I}_\textrm{acc} \cdot r_V(v_{t-1}|z_{t-1}, u_{t-1}, t, x) 
\end{split}
\end{equation}
with $r_V$ as in equation~\eqref{eq:ReverseTransitionNoAcceptance} and the updated momentum $u_{t-1} = v_{\textrm{revHD}}$. As described earlier, the $\delta$-function is replaced by an indicator function by cancelling it against the $\delta$-functions in the forward density.
\item If the previous move was rejected, we know that the current state equals the state $S_{t-1}^*$ (with the momentum negated), so
\begin{equation}
\begin{split}
&f_{S_{t-1} |A, S_t, T, X}(s_{t-1} | 0, s_t, t, x) \\
&\quad= f_{S_{t-1} |S_{t-1}^*, T, X}\big(s_{t-1} | (z_t, -v_t), t, x\big) \\
&\quad= \delta \left[z_{t-1} - z_{t} \right] \cdot r_V(v_{t-1}|z_{t-1}, -v_t, t, x) \\
&\quad= (1 - \mathbb{I}_\textrm{acc}) \cdot r_V(v_{t-1}| z_{t-1}, u_{t-1}, t, x)
\end{split}
\end{equation}
where now $u_{t-1} = -v_t$ and the $\delta$-function is again converted to an indicator function by cancellation.

If these densities are computed during the sampling process, $u_{t-1}$ is directly available and does not need to be recomputed.
\item The probability $\mathbb{P}(A = 1|S_t = s_t, t, x)$ of accepting the previous step can be simplified under certain conditions (for the derivation see appendix~\ref{app:DerivationOfReverseAcceptanceProbability}): If $H(revHD(s_t)) \leq H(s_t)$, then $\mathbb{P}(A = 1|S_t = s_t, t, x) = 1$. Otherwise, this reverse acceptance probability needs to be learnt, but will tend towards $\exp(-H(revHD(s_t)) + H(s_t))$ as the chain converges. 
\item $\mathbb{P}(A = 0|S_t = s_t, t, x) = 1 - \mathbb{P}(A = 1|S_t = s_t, t, x)$
\end{itemize}

To capture the density of the backward Markov chain, a full auxiliary reverse model should therefore consist of two parts: Firstly the density estimating model for $r_V(v_{t-1}|z_{t-1}, u_{t-1}, t, x)$ as for the case without the acceptance step and secondly a model for $\mathbb{P}(A = 1|S_t = s_t, t, x)$. Regarding $r_V$, a small difference to the case without the acceptance step is that here $v_{t-1}$ is not always the end of a previous HD simulation, but can also be equal to  $-u_{t-2}$, the updated momentum at the start of the previous simulation, if the resulting proposal was rejected. 

Putting these terms together the reverse transition density is given by
\begin{equation}
\begin{split}
r(s_{t-1} &| s_t, t, x) = r_V(v_{t-1}| z_{t-1}, u_{t-1}, t, x) \\
&\cdot \Big( \mathbb{I}_\textrm{acc} \cdot \mathbb{P}(A = 1 | s_{t}, t, x) \\
&\qquad\; + (1 - \mathbb{I}_\textrm{acc}) \cdot \mathbb{P}(A = 0 | s_{t}, t, x) \Big)
\end{split}
\end{equation}
With this last component for the computation of the auxiliary lower bound, we are now able to apply the full HMC algorithm within the MCVI framework. In particular, we recover the guaranteed convergence to the exact posterior, which was lost by skipping the acceptance step.

\subsection{Learning the mass matrix}
\label{sec:MassMatrixChoice}
In its usual application as a sampling algorithm, the freedom in the configuration of the HMC is often a curse, since a lot of parameters have to be specified, for example the mass matrix and the step size. These choices may then dramatically change the performance of the algorithm. In our application, however, we can side-step this issue by allowing all continuous parameters of the algorithm to be learnt, in particular the mass matrix $M$. As explained in section~\ref{sec:EffectOfKineticEnergyChoice}, choosing a specific mass matrix is equivalent to a rescaling of the $z$-space, which may improve the convergence of the algorithm. It is important to keep in mind, that the space is not actually transformed, but that the mass matrix makes the algorithm behave as if the space was transformed.

In addition to this indirect contribution to the lower bound through improved convergence, the mass matrix also directly appears in the lower bound as the covariance matrix of the canonical momentum distribution. From the lower bound and the transition densities derived in the previous sections we see that for each HMC step a term $-\log f_\textrm{kin}(v_\textrm{samp}|x)$ appears in the bound. $f_\textrm{kin}$ is the density of the canonical momentum distribution, a zero-mean multivariate normal distribution with covariance matrix $M$, and $v_\textrm{samp}$ is a sample from this distribution. In the lower bound the expectation of this term is taken, so the contribution to the lower bound is
\begin{equation}
\begin{split}
&\E_{f_\textrm{kin}(v|x)} \Big[ -\log f_\textrm{kin}(v|x) \Big] \\
&\quad= \frac{1}{2}\E_{f_\textrm{kin}} \left[d\log(2 \pi) + \log(|M|) +  v^T M^{-1} v \right] \\
&\quad= \frac{1}{2} \Big( d \log(2 \pi) + \log(|M|) + d \Big), 
\end{split}
\end{equation}
since $v^T M^{-1} v$ has a $\chi^2$-distribution on $d$ degrees of freedom, which therefore has expected value $d$. 

%Assuming for simplicity that $M$ is diagonal, this simplifies to
%\begin{equation}
%\begin{split}
%\E_{f_\textrm{kin}(v|x)}& \Big[ -\log f_\textrm{kin}(v|x) \Big] \\
%&= \frac{d}{2} \Big( \log(2 \pi) + 1 \Big) + \frac{1}{2} \sum_{i=1}^d \log(m_i),
%\end{split}
%\end{equation}
%where $m_i$ is the $i^{\textrm{th}}$ diagonal element of $M$.
%
In the reverse model we have the density $r_V(v_{t-1}|z_{t-1}, u_{t-1}, t, x)$ capturing the distribution of the arrival momentum. In other words, this tries to learn the momentum distribution at the end of the HD simulations. Thus, it should be closely related to the momentum distribution at the start of the HD simulations, which is exactly $f_\textrm{kin}$. In particular when assuming a multivariate normal density for $r_V$, their covariance matrices should be similar, so their direct contributions to the lower bound via forward and reverse densities should offset each other and not have a significant influence on the training of $M$.

The straight forward approach for the choice of mass matrix is to learn a single global mass matrix, which is used for all observed variables $x$. This corresponds to a global rescaling of the latent space for all computations within the algorithm. However, the potential energy $U(z)$ defining the landscape on which the dynamics are simulated, may strongly depend on $x$ (see equation~\eqref{eq:VIwithHMCPotEnergy}) and require a different rescaling for each $x$ for optimal performance. Therefore, a global rescaling will probably only have limited effect on the lower bound.

The obvious consequence of these considerations is to make the mass matrix dependent on $x$, which from a physical point of view corresponds to the masses of the simulated particles depending on the observed variable. This extension, which does not violate any theoretical considerations (see section~\ref{sec:KinEnergyMayDependOnX}), allows the optimal rescaling for each data point to be learnt and should greatly enhance the performance of the algorithm.

\subsection{Computational simplifications}

So far we have presented the theory behind HMCVI with the goal of mathematical completeness and clarity, but for an efficient implementation some simplifications can be made.

\subsubsection{Simplifications for HMCVI without partial momentum updates}
\label{sec:SimplificationWithoutPartialMomentumUpdate}
If we do not perform partial momentum updates, then the initial momentum $v_0$ is immediately replaced in the first step of the HMC algorithm. Thus, it should not influence the lower bound at all. And indeed, if $\alpha = 0$, $r(v_0|z_0, u_0, t=1, x) = f_\textrm{kin}(v_0|x)$ is the optimal choice for $r$ if $t=1$, since no more information about $v_0$ is available. In the loss only these terms contain $v_0$ and they appear with opposite sign in the loss, so by simply cancelling them instead of learning their equality we can reduce the computational load.

Furthermore, without partial momentum updates the updated momentum $u_t$ is directly sampled from the canonical momentum distribution, so it does not contain any information about the previous momentum $v_t$. Therefore, $u_t$ should not be used as an input in any of the reverse models, if $\alpha=0$. Conveniently, in this case the density predicting the arrival momentum $r_V$ has the same inputs as the final momentum model $r_\textrm{final}$, so we can combine them by setting $r_\textrm{final}(v_T | z_T, x) = r_V(v_T | z_T, T+1, x)$.

\subsubsection{Computing expectations explicitly}

The lower bound $\mathcal{L_\textrm{aux}}$ is given as the expectation of a sum of terms in equation~\eqref{eq:HMCVIAuxLowerBound}, but for some of these terms the expectation can be computed explicitly, reducing the noise in the stochastic gradient estimates used for training. In particular, the forward model density terms can usually be solved analytically, because the expectation over the sampled paths is actually the expectation over all the random variables determining this path. These random variables are the initial state sampled from $q_0$ and the various momentum updates all sampled from the canonical momentum distribution $f_\textrm{kin}$. For each of these variables the NLL appears as part of the lower bound and the expectation of the NLL of a random variable is actually its entropy, which is known in closed form for most distributions.