\section{Implementation Details}\label{ch:impl}

This section first details how the real- and complex fractional exponential functions are implemented in an efficient manner and then discusses their integration in Theano. 
Considerations about numerical accuracy and improvements in computational efficiency are covered thereafter. 

\begin{algorithm}
\begin{algorithmic}
\If {$x < 0$} 
	\Return $\exp(x) -1$
\Else
	\State $k \gets 0$
        \While{$x > 1$ \textbf{and} $k < k_{max} (=5)$}
        		\State $x \gets \log(x)$;  $k \gets k +1$	
        \EndWhile
         \State \Return $x + k$
\EndIf
\end{algorithmic}
\caption{Computation of $\psi(x)$.}
\label{alg:psi}
\end{algorithm}
\begin{algorithm}
\begin{algorithmic}
\If {$\psi < \psi_{min}$} %-0.999955
    \Return $\psiInv(\psi_{min})$ %-10
\ElsIf {$x > \psi_{max}$} %2.83403
    \Return $\psiInv(\psi_{max})$ %10
    \Else
        \State $k = \lceil \psi - 1.0 \rceil$
        \If {$k < 0$}
			\State	\Return $\log(\psi - k)$
        \EndIf
        \State $\psi \gets \psi - k$
        \While{$k > 0$}
        		\State $\psi \gets \exp(\psi)$;  $k \gets k -1$	
        \EndWhile
        \State \Return $\psi$
\EndIf
\end{algorithmic}
\caption{Computation of $\psiInv(\psi)$. 
The value for $\psiInv$ with $\psi < -1$ would mathematically be $-\infty$. 
Similarly, inputs with $\psi \gtrsim 4.406$ evaluate to values larger than can be represented with single precision floating point numbers. 
Since infinite values cause problems in gradient-based learning, we restrict $\psiInv$ to the interval $\left[-10,10\right]$. 
$\psi_{min}$ and $\psi_{max}$ are set as $\psi_{min}=-0.999955$ and $\psi_{max}=2.83403$, so that $\psiInv(\psi_{min})=-10$ and $\psiInv(\psi_{max})=10$.}
\label{alg:psiInv}
\end{algorithm}

\begin{table*}
\centering
\input{figures/table2d}
\hspace{\columnsep}
\input{figures/table3d}
\caption{Results for the interpolation of $\expn$ with method A (left) and method B (right). $r_{z}$ and $r_{n}$ are the sampling resolutions used for choosing the values to be precomputed. $t$ denotes the runtime of computing function values for one million test points and $M$ gives the required memory for the respective setting.
All GPU computations have been conducted on a Nvidia Quadro K2200. The used CPU is a Intel Xeon E3-1226 v3 @ 3.30 GHz.}
\label{tab:ip}
\end{table*}

\begin{table*}
\centering
\input{figures/table2dLatentResults}
\caption{Results for the interpolation of $\expn$ with method A (left) and method B (right). $r_{z}$ and $r_{n}$ are the sampling resolutions used for choosing the values to be precomputed. $t$ denotes the runtime of computing function values for one million test points and $M$ gives the required memory for the respective setting.
All GPU computations have been conducted on a Nvidia Quadro K2200. The used CPU is a Intel Xeon E3-1226 v3 @ 3.30 GHz.}
\end{table*}