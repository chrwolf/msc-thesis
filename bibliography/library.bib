Automatically generated by Mendeley Desktop 1.15.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{LeCun1998,
abstract = {A long and detailed paper on convolutional nets, graph transformer$\backslash$nnetworks, and discriminative training methods for sequence labeling.$\backslash$nWe show how to build systems that integrate segmentation, feature$\backslash$nextraction, classification, contextual post-processing, and language$\backslash$nmodeling into one single learning machine trained end-to-end. Applications$\backslash$nto handwriting recognition and face detection are described.},
author = {LeCun, Yann and Bottou, Leon and Bengio, Yoshua and Haffner, Patrick},
doi = {10.1109/5.726791},
isbn = {0018-9219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {character recognition,convolutional neural networks,document recog-,finite state transducers,gradient-based learning,graph,machine learning,neural networks,nition,ocr,optical,transformer networks},
number = {11},
pages = {2278--2324},
pmid = {15823584},
title = {{Gradient Based Learning Applied to Document Recognition}},
volume = {86},
year = {1998}
}
@article{Jordan1999,
abstract = {This paper presents a tutorial introduction to the use of variational$\backslash$nmethods for inference and learning in graphical models (Bayesian$\backslash$nnetworks and Markov random fields). We present a number of examples$\backslash$nof graphical models, including the QMR-DT database, the sigmoid belief$\backslash$nnetwork, the Boltzmann machine, and several variants of hidden Markov$\backslash$nmodels, in which it is infeasible to run exact inference algorithms.$\backslash$nWe then introduce variational methods, which exploit laws of large$\backslash$nnumbers to transform the original graphical model into a simplified$\backslash$ngraphical model in which inference is efficient. Inference in the$\backslash$nsimpified model provides bounds on probabilities of interest in the$\backslash$noriginal model. We describe a general framework for generating variational$\backslash$ntransformations based on convex duality. Finally we return to the$\backslash$nexamples and demonstrate how variational algorithms can be formulated$\backslash$nin each case.},
author = {Jordan, Michael I. and Ghahramani, Zoubin and Jaakkola, Tommi S. and Saul, Lawrence K.},
doi = {10.1023/A:1007665907178},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Varitional Methods Introduction.pdf:pdf},
isbn = {0262600323},
issn = {08856125},
journal = {Machine Learning},
keywords = {approximate infer-,bayesian networks,belief networks,boltzmann machines,ence,graphical models,hidden markov models,mean field methods,neural networks,probabilistic inference,variational methods},
number = {2},
pages = {183--233},
pmid = {10063011},
title = {{Introduction to variational methods for graphical models}},
volume = {37},
year = {1999}
}
@article{Kingma2014b,
author = {Kingma, Diederik P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Stochastic Backpropagation and VI.pdf:pdf},
journal = {Advances in neural information processing systems},
pages = {3581--3589},
title = {{Semi-supervised learning with deep generative models}},
year = {2014}
}
@inproceedings{Salimans2014,
abstract = {Recent advances in stochastic gradient variational inference have made it possible to perform variational Bayesian inference with posterior approximations containing auxiliary random variables. This enables us to explore a new synthesis of variational inference and Monte Carlo methods where we incorporate one or more steps of MCMC into our variational approximation. By doing so we obtain a rich class of inference algorithms bridging the gap between variational methods and MCMC, and offering the best of both worlds: fast posterior approximation through the maximization of an explicit objective, with the option of trading off additional computation for additional accuracy. We describe the theoretical foundations that make this possible and show some promising first results.},
author = {Salimans, Tim and Kingma, Diederik P. and Welling, Max},
booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/MCMC and Variational Inference.pdf:pdf},
pages = {1218--1226},
title = {{Markov Chain Monte Carlo and Variational Inference: Bridging the Gap}},
url = {http://arxiv.org/abs/1410.6460},
year = {2015}
}
@article{Dinh2014,
abstract = {We propose a deep learning framework for modeling complex high-dimensional densities via Non-linear Independent Component Estimation (NICE). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the determinant of the Jacobian and inverse Jacobian is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep neural network. The training criterion is simply the exact log-likelihood, which is tractable, and unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.},
author = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/NICE.pdf:pdf},
journal = {International Conference on Learning Representations 2015},
title = {{NICE: Non-linear Independent Components Estimation}},
url = {http://arxiv.org/abs/1410.8516},
year = {2015}
}
@inproceedings{Sohl-Dickstein2014,
abstract = {We present a method for performing Hamiltonian Monte Carlo that largely eliminates sample rejection. In situations that would normally lead to rejection, instead a longer trajectory is computed until a new state is reached that can be accepted. This is achieved using Markov chain transitions that satisfy the fixed point equation, but do not satisfy detailed balance. The resulting algorithm significantly suppresses the random walk behavior and wasted function evaluations that are typically the consequence of update rejection. We demonstrate a greater than factor of two improvement in mixing time on three test problems. We release the source code as Python and MATLAB packages.},
archivePrefix = {arXiv},
arxivId = {arXiv:1409.5191v2},
author = {Sohl-Dickstein, J and Mudigonda, Mayur and DeWeese, M},
booktitle = {Proceedings of The 31st International Conference on Machine Learning},
eprint = {arXiv:1409.5191v2},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/HMC without Detailed Balance.pdf:pdf},
isbn = {9781634393973},
pages = {9},
title = {{Hamiltonian Monte Carlo Without Detailed Balance}},
url = {http://jmlr.org/proceedings/papers/v32/sohl-dickstein14.html},
volume = {32},
year = {2014}
}
@article{Rumelhart1986,
abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vecotr of the net and the desired output vector. As a result of the weight adjustments, internal 'hidden' units wich are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpoler methods such as the perceptron-convergence procedure.},
author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
doi = {10.1038/323533a0},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Backpropagation.pdf:pdf},
isbn = {0262661160},
issn = {0028-0836},
journal = {Nature},
number = {6088},
pages = {533--536},
pmid = {134},
title = {{Learning representations by back-propagating errors}},
volume = {323},
year = {1986}
}
@article{Girolami2011,
abstract = {The paper proposes Metropolis adjusted Langevin and Hamiltonian Monte Carlo sampling methods defined on the Riemann manifold to resolve the shortcomings of existing Monte Carlo algorithms when sampling from target densities that may be high dimensional and exhibit strong correlations. The methods provide fully automated adaptation mechanisms that circumvent the costly pilot runs that are required to tune proposal densities for Metropolis-Hastings or indeed Hamiltonian Monte Carlo and Metropolis adjusted Langevin algorithms. This allows for highly efficient sampling even in very high dimensions where different scalings may be required for the transient and stationary phases of the Markov chain. The methodology proposed exploits the Riemann geometry of the parameter space of statistical models and thus automatically adapts to the local structure when simulating paths across this manifold, providing highly efficient convergence and exploration of the target density. The performance of these Riemann manifold Monte Carlo methods is rigorously assessed by performing inference on logistic regression models, log-Gaussian Cox point processes, stochastic volatility models and Bayesian estimation of dynamic systems described by non-linear differential equations. Substantial improvements in the time-normalized effective sample size are reported when compared with alternative sampling approaches. MATLAB code that is available from http://www.ucl.ac.uk/statistics/research/rmhmc allows replication of all the results reported.},
author = {Girolami, Mark and Calderhead, Ben},
doi = {10.1111/j.1467-9868.2010.00765.x},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Riemann manifold Langevin and HMC methods.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Bayesian inference,Geometry in statistics,Hamiltonian Monte Carlo methods,Langevin diffusion,Markov chain Monte Carlo methods,Riemann manifolds},
number = {2},
pages = {123--214},
title = {{Riemann manifold Langevin and Hamiltonian Monte Carlo methods}},
volume = {73},
year = {2011}
}
@article{Bennett1975,
abstract = {If one replaces the ordinary kinetic energy function for a classical system of point masses ((12 $\Sigma$i=1N miq̇i2) by a more general quadratic form (12 $\Sigma$ij=1N q̇iMijq̇j), where Mij is an arbitrary positive-definite symmetric “mass tensor,” one obtains a system having different dynamics but the same equilibrium properties as the original system. By appropriate choice of Mij, high frequency motions can be slowed down and low frequency ones speeded up, thereby increasing the efficiency with which configuration space can be explored in a given amont of computer time. Tests of the method on a short Lennard-Jones polymer chain indicate that a five- to tenfold saving of computer time is possible for such systems.},
author = {Bennett, Charles H.},
doi = {10.1016/0021-9991(75)90077-7},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Mass tensor molecular dynamics.pdf:pdf},
issn = {00219991},
journal = {Journal of Computational Physics},
number = {3},
pages = {267--279},
title = {{Mass tensor molecular dynamics}},
url = {http://www.sciencedirect.com/science/article/pii/0021999175900777},
volume = {19},
year = {1975}
}
@article{Kingma2015,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions. The method is straightforward to implement and is based on adaptive estimates of lower-order moments of the gradients. The method is computationally efficient, has little memory requirements and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The method exhibits invariance to diagonal rescaling of the gradients by adapting to the geometry of the objective function. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. We demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods.},
author = {Kingma, Diederik P. and Ba, Jimmy Lei},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Adam - A Method for Stochastic Optimization.pdf:pdf},
journal = {International Conference on Learning Representations 2015},
title = {{Adam: a Method for Stochastic Optimization}},
year = {2015}
}
@misc{Salimans2014b,
author = {Salimans, Tim and Welling, Max},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/salimans{\_}vi{\_}nips2014.pdf:pdf},
title = {{MCMC and VI Lecture}},
year = {2014}
}
@inproceedings{Bergstra2010,
abstract = {Theano is a compiler for mathematical expressions in Python that combines the convenience of NumPy’s syntax with the speed of optimized native machine language. The user composes mathematical expressions in a high-level description that mimics NumPy’s syntax and semantics, while being statically typed and functional (as opposed to imperative). These expressions allow Theano to provide symbolic differentiation. Before performing computation, Theano optimizes the choice of expressions, translates them into C++ (or CUDA for GPU), compiles them into dynamically loaded Python modules, all automatically. Common machine learning algorithms implemented with Theano are from 1:6 to 7:5 faster than competitive alternatives (including those implemented with C/C++, NumPy/SciPy and MATLAB) when compiled for the CPU and between 6:5 and 44 faster when compiled for the GPU. This paper illustrates how to use Theano, outlines the scope of the compiler, provides benchmarks on both CPU and GPU processors, and explains its overall design},
author = {Bergstra, James and Breuleux, Olivier and Bastien, Frederic and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
booktitle = {9th Python in Science Conference (SciPy)},
file = {:Users/christopher/Library/Application Support/Mendeley Desktop/Downloaded/Bergstra et al. - 2010 - Theano a CPU and GPU math compiler in Python.pdf:pdf},
title = {{Theano: a CPU and GPU math compiler in Python}},
url = {http://www-etud.iro.umontreal.ca/{~}wardefar/publications/theano{\_}scipy2010.pdf},
year = {2010}
}
@inproceedings{Rezende2014,
abstract = {We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation -- rules for back-propagation through stochastic variables -- and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.},
author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
booktitle = {Proceedings of the 31st International Conference on Machine Learning},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Stochastic Backpropagation and Approximate Inference in Deep Generative Models.pdf:pdf},
isbn = {9781634393973},
pages = {1278--1286},
title = {{Stochastic Backpropagation and Approximate Inference in Deep Generative Models}},
url = {http://arxiv.org/abs/1401.4082 http://jmlr.org/proceedings/papers/v32/rezende14.html$\backslash$npapers3://publication/uuid/F2747569-7719-4EAC-A5A7-9ECA9D6A8FE6},
year = {2014}
}
@article{Jung2012,
abstract = {This paper develops generalizations of empowerment to continuous states. Empowerment is a recently introduced information-theoretic quantity motivated by hypotheses about the efficiency of the sensorimotor loop in biological organisms, but also from considerations stemming from curiosity-driven learning. Empowemerment measures, for agent-environment systems with stochastic transitions, how much influence an agent has on its environment, but only that influence that can be sensed by the agent sensors. It is an information-theoretic generalization of joint controllability (influence on environment) and observability (measurement by sensors) of the environment by the agent, both controllability and observability being usually defined in control theory as the dimensionality of the control/observation spaces. Earlier work has shown that empowerment has various interesting and relevant properties, e.g., it allows us to identify salient states using only the dynamics, and it can act as intrinsic reward without requiring an external reward. However, in this previous work empowerment was limited to the case of small-scale and discrete domains and furthermore state transition probabilities were assumed to be known. The goal of this paper is to extend empowerment to the significantly more important and relevant case of continuous vector-valued state spaces and initially unknown state transition probabilities. The continuous state space is addressed by Monte-Carlo approximation; the unknown transitions are addressed by model learning and prediction for which we apply Gaussian processes regression with iterated forecasting. In a number of well-known continuous control tasks we examine the dynamics induced by empowerment and include an application to exploration and online model learning.},
archivePrefix = {arXiv},
arxivId = {1201.6583},
author = {Jung, Tobias and Polani, Daniel and Stone, Peter},
eprint = {1201.6583},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Empowerment for Continuous Agent-Environment Systems.pdf:pdf},
title = {{Empowerment for Continuous Agent-Environment Systems}},
url = {http://arxiv.org/abs/1201.6583},
year = {2012}
}
@article{Neal1993,
abstract = {Probabilistic inference is an attractive approach to uncertain reasoning and empirical learning in artificial intelligence. Computational difficulties arise, however, because probabilistic models with the necessary realism and flexibility lead to complex distributions over high-dimensional spaces. Related problems in other fields have been tackled using Monte Carlo methods based on sampling using Markov chains, providing a rich array of techniques that can be applied to problems in artificial intelligence. The "Metropolis algorithm" has been used to solve difficult problems in statistical physics for over forty years, and, in the last few years, the related method of "Gibbs sampling" has been applied to problems of statistical inference. Concurrently, an alternative method for solving problems in statistical physics by means of dynamical simulation has been developed as well, and has recently been unified with the Metropolis algorithm to produce the "hybrid Monte Carlo" method. In computer science, Markov chain sampling is the basis of the heuristic optimization technique of "simulated annealing", and has recently been used in randomized algorithms for approximate counting of large sets. In this review, I outline the role of probabilistic inference in artificial intelligence, present the theory of Markov chains, and describe various Markov chain Monte Carlo algorithms, along with a number of supporting techniques. I try to present a comprehensive picture of the range of methods that have been developed, including techniques from the varied literature that have not yet seen wide application in artificial intelligence, but which appear relevant. As illustrative examples, I use the problems of probabilistic inference in expert systems, discovery of latent classes from data, and Bayesian learning for neural networks.},
author = {Neal, Radford M},
doi = {10.1016/j.neuroimage.2009.01.023},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Probabilistic Inference using MCMC methods.pdf:pdf},
issn = {10959572},
journal = {Intelligence},
number = {September},
pages = {144},
pmid = {19349224},
title = {{Probabilistic Inference Using Markov Chain Monte Carlo Methods Acknowledgements}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.9055{\&}amp;rep=rep1{\&}amp;type=pdf},
volume = {45},
year = {1993}
}
@book{MacKay2005,
abstract = {This book is aimed at senior undergraduates and graduate students in Engineering, Science, Mathematics, and Computing. It expects familiarity with calculus, probability theory, and linear algebra as taught in a rst- or secondyear undergraduate course on mathematics for scientists and engineers. Conventional courses on information theory cover not only the beautiful theoretical ideas of Shannon, but also practical solutions to communication problems. This book goes further, bringing in Bayesian data modelling, Monte Carlo methods, variational methods, clustering algorithms, and neural networks. Why unify information theory and machine learning? Because they are two sides of the same coin. In the 1960s, a single eld, cybernetics, was populated by information theorists, computer scientists, and neuroscientists, all studying common problems. Information theory and machine learning still belong together. Brains are the ultimate compression and communication systems. And the state-of-the-art algorithms for both data compression and error-correcting codes use the same tools as machine learning.},
author = {MacKay, David J C},
booktitle = {Learning},
doi = {10.1198/jasa.2005.s54},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Information Theory, Inference and Learning Algorithms.pdf:pdf},
isbn = {9780521642989},
issn = {01621459},
pages = {1--640},
title = {{Information Theory, Inference, and Learning Algorithms David J.C. MacKay}},
url = {http://pubs.amstat.org/doi/abs/10.1198/jasa.2005.s54$\backslash$nhttp://www.cambridge.org/0521642981},
volume = {100},
year = {2005}
}
@article{Hinton2012,
abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
archivePrefix = {arXiv},
arxivId = {1207.0580},
author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
doi = {arXiv:1207.0580},
eprint = {1207.0580},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Dropout.pdf:pdf},
title = {{Improving neural networks by preventing co-adaptation of feature detectors}},
url = {http://arxiv.org/abs/1207.0580},
year = {2012}
}
@article{Hoffman2013,
abstract = {We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.},
author = {Hoffman, Matt and Blei, David M. and Wang, Chong and Paisley, John},
doi = {citeulike-article-id:10852147},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Stochastic VI.pdf:pdf},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
number = {3},
pages = {1303--1347},
title = {{Stochastic Variational Inference}},
url = {http://arxiv.org/abs/1206.7051 http://arxiv.org/abs/1206.7051$\backslash$npapers2://publication/uuid/D5737928-F59F-43E3-8ADE-53F1831AA866},
volume = {14},
year = {2013}
}
@misc{VanderSmagt2013,
author = {van der Smagt, Patrick},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Writing Papers In LaTeX.pdf:pdf},
pages = {1--6},
title = {{TEXing Guide}},
year = {2013}
}
@article{Ioffe2015,
abstract = {{Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch{\}}. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9{\%} top-5 validation error (and 4.8{\%} test error), exceeding the accuracy of human raters.},
archivePrefix = {arXiv},
arxivId = {1502.03167},
author = {Ioffe, Sergey and Szegedy, Christian},
eprint = {1502.03167},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Batch Normalization.pdf:pdf},
title = {{Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}},
url = {http://arxiv.org/abs/1502.03167},
year = {2015}
}
@book{Bickel2009,
author = {Bickel, Edited P and Diggle, P and Fienberg, S and Gather, U},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Topics in Statistical Information Theory.pdf:pdf},
isbn = {9783642124648},
pages = {341},
title = {{Lecture Notes in Statistics – Proceedings}},
year = {2009}
}
@article{Kingma2014,
abstract = {Can we efficiently learn the parameters of directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce an unsupervised on-line learning algorithm that efficiently optimizes the variational lower bound on the marginal likelihood and that, under some mild conditions, even works in the intractable case. The algorithm, Stochastic Gradient Variational Bayes (SGVB), optimizes a probabilistic encoder (also called a recognition model) to approximate the intractable posterior distribution of the latent variables. Crucial is a reparameterization of the variational bound with an independent noise variable, yielding a stochastic objective function which can be jointly optimized w.r.t. variational and generative parameters using standard gradient-based stochastic optimization methods. Theoretical advantages are reflected in experimental results.},
author = {Kingma, Diederik P and Welling, Max},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Stochastic Gradient VB and the Variational Auto-Encoder.pdf:pdf},
journal = {International Conference on Learning Representations 2014},
title = {{Stochastic Gradient VB and the Variational Auto-Encoder}},
url = {http://arxiv.org/abs/1312.6114},
year = {2014}
}
@inproceedings{Rezende2015,
abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Variational Inference with Normalizing Flows.pdf:pdf},
pages = {1530--1538},
title = {{Variational Inference with Normalizing Flows}},
url = {http://arxiv.org/abs/1505.05770},
year = {2015}
}
@inproceedings{Gregor2015,
abstract = {This paper introduces the Deep Recurrent Atten-tive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distin-guished from real data with the naked eye.},
author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and {Jimenez Rezende}, Danilo and Wierstra, Daan},
booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/DRAW.pdf:pdf},
pages = {1462--1471},
title = {{DRAW: A Recurrent Neural Network For Image Generation}},
year = {2015}
}
@article{Betancourt2014,
abstract = {Although Hamiltonian Monte Carlo has proven an empirical success, the lack of a rigorous theoretical understanding of the algorithm has in many ways impeded both principled developments of the method and use of the algorithm in practice. In this paper we develop the formal foundations of the algorithm through the construction of measures on smooth manifolds, and demonstrate how the theory naturally identifies efficient implementations and motivates promising generalizations.},
archivePrefix = {arXiv},
arxivId = {1410.5110},
author = {Betancourt, M J and Byrne, Simon and Livingstone, Samuel and Girolami, Mark},
eprint = {1410.5110},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/The Geometric Foundations of HMC.pdf:pdf},
keywords = {and phrases,bundle,carlo,differential geometry,disintegration,fiber,hamiltonian monte,inference requires algorithms capable,markov chain monte carlo,of fitting complex mod-,riemannian geometry,smooth manifold,symplectic geometry,the frontier of bayesian},
title = {{The Geometric Foundations of Hamiltonian Monte Carlo}},
url = {http://arxiv.org/abs/1410.5110v1$\backslash$npapers2://publication/uuid/7D906BF6-2FFE-4AC3-9A60-C68E3CCBF6F7},
year = {2014}
}
@article{Kingma2013,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
eprint = {1312.6114},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Auto-Encoding Variational Bayes.pdf:pdf},
journal = {arXiv preprint arXiv:1312.6114},
title = {{Auto-Encoding Variational Bayes}},
url = {http://xxx.tau.ac.il/pdf/1312.6114v1.pdf$\backslash$nhttp://arxiv.org/abs/1312.6114 http://arxiv.org/abs/1312.6114},
year = {2013}
}
@article{Duchi2011,
abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.},
author = {Duchi, John and Hazan, Elad and Singer, Yoram},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/AdaGrad.pdf:pdf},
isbn = {9780982252925},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {adaptivity,online learning,stochastic convex optimization,subgradient methods},
pages = {2121--2159},
title = {{Adaptive Subgradient Methods for Online Learning and Stochastic Optimization}},
url = {http://jmlr.org/papers/v12/duchi11a.html},
volume = {12},
year = {2011}
}
@article{Bastien2012,
abstract = {Theano is a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations. In this paper, we present new features and efficiency improvements to Theano, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks.},
author = {Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Bergstra, James and Goodfellow, Ian and Bergeron, Arnaud and Bouchard, Nicolas and Warde-Farley, David and Bengio, Yoshua},
journal = {Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop},
title = {{Theano: new features and speed improvements}},
url = {http://arxiv.org/abs/1211.5590},
year = {2012}
}
@article{Neal2011,
abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard-to-compute Jacobian factor - a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, I discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for deciding on acceptance or rejection, computing trajectories using fast approximations, tempering during the course of a trajectory to handle isolated modes, and short-cut methods that prevent useless trajectories from taking much computation time.},
author = {Neal, Radford M.},
doi = {doi:10.1201/b10905-6},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/MCMC using Hamiltonian dynamics.pdf:pdf},
isbn = {9781420079418},
issn = {<null>},
journal = {Handbook of Markov Chain Monte Carlo},
keywords = {hamiltonian dynamics,mcmc},
pages = {113--162},
title = {{MCMC using Hamiltonian dynamics}},
url = {http://arxiv.org/abs/1206.1901},
year = {2011}
}
@article{Roberts2004,
abstract = {This paper surveys various results about Markov chains on general (non-countable) state spaces. It begins with an introduction to Markov chain Monte Carlo (MCMC) algorithms, which provide the motivation and context for the theory which follows. Then, sufficient conditions for geometric and uniform ergodicity are presented, along with quantitative bounds on the rate of convergence to stationarity. Many of these results are proved using direct coupling constructions based on minorisation and drift conditions. Necessary and sufficient conditions for Central Limit Theorems (CLTs) are also presented, in some cases proved via the Poisson Equation or direct regeneration constructions. Finally, optimal scaling and weak convergence results for Metropolis-Hastings algorithms are discussed. None of the results presented is new, though many of the proofs are. We also describe some Open Problems.},
author = {Roberts, Gareth O and Rosenthal, Jeffrey S},
doi = {10.1214/154957804100000024},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/General state space Markov chains and MCMC algorithms.pdf:pdf},
isbn = {1549-5787},
issn = {1549-5787},
journal = {Probability Surveys},
keywords = {qa mathematics},
pages = {20--71},
title = {{General state space Markov chains and MCMC algorithms.}},
url = {http://arxiv.org/abs/math/0404033},
volume = {1},
year = {2004}
}
@article{Wager2013,
abstract = {Dropout and other feature noising schemes control overﬁtting by artiﬁcially corrupting the training data. For generalized linear models, dropout performs a form of adaptive regularization. Using this viewpoint, we show that the dropout regularizer is ﬁrst-order equivalent to an L2 regularizer applied after scaling the features by an estimate of the inverse diagonal Fisher information matrix. We also establish a connection to AdaGrad, an online learning algorithm, and ﬁnd that a close relative of AdaGrad operates by repeatedly solving linear dropout-regularized problems. By casting dropout as regularization, we develop a natural semi-supervised algorithm that uses unlabeled data to create a better adaptive regularizer. We apply this idea to document classiﬁcation tasks, and show that it consistently boosts the performance of dropout training, improving on state-of-the-art results on the IMDB reviews dataset.},
archivePrefix = {arXiv},
arxivId = {arXiv:1307.1493v2},
author = {Wager, Stefan and Wang, Sida and Liang, Percy},
eprint = {arXiv:1307.1493v2},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Dropout Training as Adaptive Regularization.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information {\ldots}},
pages = {1--11},
title = {{Dropout Training as Adaptive Regularization}},
url = {http://papers.nips.cc/paper/4882-dropout-training-as-adaptive-regularization},
year = {2013}
}
@article{Wang2013,
abstract = {Preventing feature co-adaptation by encouraging independent contributions from different features often improves classification and regression performance. Dropout training (Hinton et al., 2012) does this by randomly dropping out (zeroing) hidden units and input features during training of neural networks. However, repeatedly sampling a random subset of input features makes training much slower. Based on an examination of the implied objective function of dropout training, we show how to do fast dropout training by sampling from or integrating a Gaussian approximation, instead of doing Monte Carlo optimization of this objective. This approximation, justified by the central limit theorem and empirical evidence, gives an order of magnitude speedup and more stability. We show how to do fast dropout training for classification, regression, and multilayer neural networks. Beyond dropout, our technique is extended to integrate out other types of noise and small image transformations.},
author = {Wang, Sida I and Manning, Christopher D},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Fast Dropout.pdf:pdf},
journal = {Proceedings of the 30th International Conference on Machine Learning},
keywords = {I,boring formatting information,machine learning},
pages = {118--126},
title = {{Fast dropout training}},
url = {http://machinelearning.wustl.edu/mlpapers/papers/wang13a},
volume = {28},
year = {2013}
}
@inproceedings{Paisley2012,
abstract = {Mean-field variational inference is a method for approximate Bayesian posterior inference. It approximates a full posterior distribution with a factorized set of distributions by maximizing a lower bound on the marginal likelihood. This requires the ability to integrate a sum of terms in the log joint likelihood using this factorized distribution. Often not all integrals are in closed form, which is typically handled by using a lower bound. We present an alternative algorithm based on stochastic optimization that allows for direct optimization of the variational lower bound. This method uses control variates to reduce the variance of the stochastic search gradient, in which existing lower bounds can play an important role. We demonstrate the approach on two non-conjugate models: logistic regression and an approximation to the HDP.},
author = {Paisley, John and Blei, David and Jordan, Michael},
booktitle = {Proceedings of the 29th International Conference on Machine Learning},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Variational Bayesian Inference with Stochastic Search.pdf:pdf},
isbn = {978-1-4503-1285-1},
pages = {1367--1374},
title = {{Variational Bayesian Inference with Stochastic Search}},
url = {http://icml.cc/2012/papers/687.pdf},
year = {2012}
}
@article{Chib2001,
abstract = {This article provides a framework for estimating the marginal likelihood for the purpose of Bayesian model comparisons. The approach extends and completes the method presented in Chib (1995) by overcoming the problems associated with the presence of intractable full conditional densities. The proposed method is developed in the context of MCMC chains produced by the Metropolis–Hastings algorithm, whose building blocks are used both for sampling and marginal likelihood estimation, thus economizing on prerun tuning effort and programming. Experiments involving the logit model for binary data, hierarchical random effects model for clustered Gaussian data, Poisson regression model for clustered count data, and the multivariate probit model for correlated binary data, are used to illustrate the performance and implementation of the method. These examples demonstrate that the method is practical and widely applicable.},
author = {Chib, Siddhartha and Jeliazkov, Ivan},
doi = {10.1198/016214501750332848},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Marginal Likelihood from Metropolis-Hastings Output.pdf:pdf},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
number = {453},
pages = {270--281},
pmid = {12510683},
title = {{Marginal Likelihood From the Metropolis–Hastings Output}},
volume = {96},
year = {2001}
}
@techreport{Bayer2015,
author = {Bayer, Justin and Osendorfer, Christian and Diot-Girard, Sarah and R{\"{u}}ckstiess, Thomas and Urban, Sebastian},
institution = {Technische Universit{\"{a}}t M{\"{u}}nchen},
keywords = {climin,python},
mendeley-tags = {climin,python},
title = {{climin - A pythonic framework for gradient-based function optimization}},
url = {http://climin.readthedocs.org},
year = {2015}
}
@article{Duane1987,
abstract = {We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons.},
author = {Duane, Simon and Kennedy, A.D. and Pendleton, Brian J. and Roweth, Duncan},
doi = {10.1016/0370-2693(87)91197-X},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Hybrid Monte Carlo.pdf:pdf},
isbn = {0370-2693},
issn = {03702693},
journal = {Physics Letters B},
number = {2},
pages = {216--222},
title = {{Hybrid Monte Carlo}},
volume = {195},
year = {1987}
}
@article{LeCun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6184v5},
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
eprint = {arXiv:1312.6184v5},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Deep Learning Review.pdf:pdf},
isbn = {3135786504},
issn = {0028-0836},
journal = {Nature},
number = {7553},
pages = {436--444},
pmid = {26017442},
title = {{Deep learning}},
url = {http://dx.doi.org/10.1038/nature14539$\backslash$n10.1038/nature14539},
volume = {521},
year = {2015}
}
@inproceedings{Salakhutdinov2008,
abstract = {Deep Belief Networks (DBN’s) are generative models that contain many layers of hidden variables. Efficient greedy algorithms for learning and approximate inference have allowed these models to be applied successfully in many application domains. The main building block of a DBN is a bipartite undirected graphical model called a restricted Boltzmann machine (RBM). Due to the presence of the partition function, model selection, complexity control, and exact maximum likelihood learning in RBM's are intractable. We show that Annealed Importance Sampling (AIS) can be used to efficiently estimate the partition function of an RBM, and we present a novel AIS scheme for comparing RBM's with different architectures. We further show how an AIS estimator, along with approximate inference, can be used to estimate a lower bound on the log-probability that a DBN model with multiple hidden layers assigns to the test data. This is, to our knowledge, the first step towards obtaining quantitative results that would allow us to directly assess the performance of Deep Belief Networks as generative models of data.},
author = {Salakhutdinov, Ruslan and Murray, Iain},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
doi = {10.1145/1390156.1390266},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Binarized MNIST Ursprungspaper.pdf:pdf},
isbn = {978-1-60558-205-4},
issn = {1605582050},
keywords = {binarized},
mendeley-tags = {binarized},
pages = {872--879},
title = {{On the quantitative analysis of Deep Belief Networks}},
url = {http://hdl.handle.net/1842/4588},
year = {2008}
}
@article{Theis2015,
abstract = {Probabilistic generative models can be used for compression, denoising, inpaint- ing, texture synthesis, semi-supervised learning, unsupervised feature learning, and other tasks. Given this wide range of applications, it is not surprising that a lot of heterogeneity exists in the way image models are formulated, trained, and evaluated. As a consequence, direct comparison between image models is often difficult. This article reviews mostly known but often underappreciated properties relating to the evaluation and interpretation of generative models. In particular, we show that three of the currently most commonly used criteria—average log- likelihood, Parzen window estimates, and visual fidelity of samples—are largely independent of each other when images are high-dimensional. Good performance with respect to one criterion therefore need not imply good performance with re- spect to the other criteria. Our results show that extrapolation from one criterion to another is not warranted and generative models need to be evaluated directly with respect to the application(s) they were intended for. In addition, we pro- vide examples demonstrating that Parzen window estimates should generally be avoided.},
archivePrefix = {arXiv},
arxivId = {1511.01844},
author = {Theis, Lucas and van den Oord, A{\"{a}}ron and Bethge, Matthias},
eprint = {1511.01844},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Evaluation of Generative Models.pdf:pdf},
journal = {arXiv preprint arXiv:1511.01844},
title = {{A note on the evaluation of generative models}},
url = {http://arxiv.org/abs/1511.01844},
year = {2015}
}
@phdthesis{Koepp2015,
author = {Koepp, Wiebke},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Wiebke Masterarbeit.pdf:pdf},
title = {{A Novel Transfer Function for Continuous Interpolation between Summation and Multiplication in Neural Networks}},
year = {2015}
}
@article{Horowitz1991,
abstract = {A hamiltonian-guided Monte Carlo algorithm for simulations of lattice field theories is presented. It is a generalization of the Hybrid Monte Carlo algorithm allowing the trajectory length to be shrunk to the step-size without losing on the speed of configuration decorrelation. Without the Monte Carlo step, this limit of the generalized algorithm reduces to the second-order Langevin equation. The latter is shown in a gaussian model and in compact QED to be faster than the Hybrid algorithm. The performance of the two algorithms with the Monte Carlo step, HMC and L2MC, turned out to be comparable in compact QED. It is pointed out that L2MC is safer from rounding errors.},
author = {Horowitz, Alan M.},
doi = {10.1016/0370-2693(91)90812-5},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/Generalized guided MC algorithm - Partial Momentum.pdf:pdf},
issn = {03702693},
journal = {Physics Letters B},
number = {2},
pages = {247--252},
title = {{A generalized guided Monte Carlo algorithm}},
url = {http://www.sciencedirect.com/science/article/pii/0370269391908125},
volume = {268},
year = {1991}
}
@misc{Blei2002,
author = {Blei, David M.},
file = {:Users/christopher/Documents/Masterarbeit/Literatur/VI{\_}Lecture.pdf:pdf},
pages = {1--12},
title = {{Variational Inference}},
year = {2002}
}
