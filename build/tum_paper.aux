\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{biblatex}
\bibdata{tum_paper-blx,bibliography/library}
\citation{biblatex-control}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Jordan1999}
\citation{Hoffman2013}
\citation{Gregor2015}
\citation{Rezende2014}
\citation{Kingma2014}
\citation{Rezende2015}
\citation{Salimans2014}
\citation{Salimans2014}
\citation{Salimans2014}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\abx@aux@page{1}{1}
\abx@aux@page{2}{1}
\abx@aux@page{3}{1}
\abx@aux@page{4}{1}
\abx@aux@page{5}{1}
\abx@aux@page{6}{1}
\abx@aux@page{7}{1}
\abx@aux@page{8}{1}
\abx@aux@page{9}{1}
\citation{Roberts2004}
\citation{Roberts2004}
\citation{Salimans2014}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Variational Inference and MCMC}{2}{section.2}}
\newlabel{sec:VIandMCMC}{{2}{2}{}{section.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Variational Inference}{2}{subsection.2.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}MCMC}{2}{subsection.2.2}}
\newlabel{sec:MCMC}{{2.2}{2}{}{subsection.2.2}{}}
\abx@aux@page{10}{2}
\newlabel{eq:Metropolis-Hastings}{{2}{2}{}{equation.2.2}{}}
\abx@aux@page{11}{2}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Combining variational inference and MCMC}{2}{subsection.2.3}}
\newlabel{sec:MCVI}{{2.3}{2}{}{subsection.2.3}{}}
\abx@aux@page{12}{2}
\citation{Kingma2014}
\citation{Rezende2014}
\citation{Kingma2015}
\citation{Duane1987}
\citation{Neal2011}
\citation{Neal2011}
\newlabel{eq:MCVIAuxLowerBound}{{4}{3}{}{equation.2.4}{}}
\abx@aux@page{13}{3}
\abx@aux@page{14}{3}
\abx@aux@page{15}{3}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Hamiltonian Monte Carlo}{3}{section.3}}
\newlabel{sec:HMC}{{3}{3}{}{section.3}{}}
\abx@aux@page{16}{3}
\abx@aux@page{17}{3}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Hamiltonian Dynamics}{3}{subsection.3.1}}
\newlabel{eq:HamiltonsEquations}{{5}{3}{}{equation.3.5}{}}
\newlabel{eq:NewtonsEquation}{{6}{3}{}{equation.3.6}{}}
\abx@aux@page{18}{3}
\citation{Neal2011}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Dynamics of a particle under HD computed using the leapfrog method. Each computed point along the discretized trajectory is indicated by a separate color ranging from dark blue (starting point) to dark red (final point). The left plot shows the position of the particle with the prescribed potential energy represented by the contour plot. The centre plot depicts the momentum of the particle with the kinetic energy at each point indicated by the contours. In the plot on the right the energy distribution of the particle over time is given, with the potential energy in blue and the kinetic energy in red. Due to the discretization the total energy is not exactly conserved.}}{4}{figure.1}}
\newlabel{fig:HMC_MOTION_1hmc_12lf}{{1}{4}{Dynamics of a particle under HD computed using the leapfrog method. Each computed point along the discretized trajectory is indicated by a separate color ranging from dark blue (starting point) to dark red (final point). The left plot shows the position of the particle with the prescribed potential energy represented by the contour plot. The centre plot depicts the momentum of the particle with the kinetic energy at each point indicated by the contours. In the plot on the right the energy distribution of the particle over time is given, with the potential energy in blue and the kinetic energy in red. Due to the discretization the total energy is not exactly conserved}{figure.1}{}}
\abx@aux@page{19}{4}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}The HMC algorithm}{4}{subsection.3.2}}
\newlabel{sec:HMCAlgorithmSection}{{3.2}{4}{}{subsection.3.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Relating probability density to energy}{4}{subsubsection.3.2.1}}
\citation{Betancourt2014}
\citation{Girolami2011}
\citation{Betancourt2014}
\citation{Neal2011}
\citation{Neal2011}
\newlabel{eq:JointDensity}{{9}{5}{}{equation.3.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Choice of kinetic energy}{5}{subsubsection.3.2.2}}
\abx@aux@page{20}{5}
\abx@aux@page{21}{5}
\abx@aux@page{22}{5}
\newlabel{eq:KineticEnergy}{{10}{5}{}{equation.3.10}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}The algorithm}{5}{subsubsection.3.2.3}}
\abx@aux@page{23}{5}
\newlabel{eq:AcceptanceProbability}{{11}{5}{}{equation.3.11}{}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces The HMC algorithm}}{5}{algorithm.1}}
\newlabel{alg:HMC}{{1}{5}{}{algorithm.1}{}}
\abx@aux@page{24}{5}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Evolution of a particle under the HMC algorithm with 3 HMC steps consisting of 4 leapfrog steps each. Each computed point along the trajectory is indicated by a separate color ranging from dark blue (starting point) to dark red (final point). Thicker dots highlight points, where momentum resampling was performed. The left plot shows the position of the particle with the prescribed potential energy represented by the contour plot. The centre plot depicts the momentum of the particle with the kinetic energy at each point indicated by the contours. Where the momentum was resampled, two identical dots are shown for the state before and after the resampling. In the plot on the right the energy distribution of the particle over time is given, with the potential energy in blue and the kinetic energy in red.}}{6}{figure.2}}
\newlabel{fig:HMC_MOTION_3hmc_04lf}{{2}{6}{Evolution of a particle under the HMC algorithm with 3 HMC steps consisting of 4 leapfrog steps each. Each computed point along the trajectory is indicated by a separate color ranging from dark blue (starting point) to dark red (final point). Thicker dots highlight points, where momentum resampling was performed. The left plot shows the position of the particle with the prescribed potential energy represented by the contour plot. The centre plot depicts the momentum of the particle with the kinetic energy at each point indicated by the contours. Where the momentum was resampled, two identical dots are shown for the state before and after the resampling. In the plot on the right the energy distribution of the particle over time is given, with the potential energy in blue and the kinetic energy in red}{figure.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Effect of the kinetic energy covariance matrix}{6}{subsection.3.3}}
\newlabel{sec:EffectOfKineticEnergyChoice}{{3.3}{6}{}{subsection.3.3}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Evolution of an ensemble of 1000 particles under the HMC algorithm: The first row of plots shows the initial state of the system and the second row the state after an HMC step. The plots on the left give the positions of the particles with the prescribed potential energy represented by the contour plot. The centre plots depict the arrival momenta of the particles with the kinetic energy indicated by the contours. The right-hand plots show histograms of the potential energies of the particles.}}{7}{figure.3}}
\newlabel{fig:HMC_Effect_Illustration}{{3}{7}{Evolution of an ensemble of 1000 particles under the HMC algorithm: The first row of plots shows the initial state of the system and the second row the state after an HMC step. The plots on the left give the positions of the particles with the prescribed potential energy represented by the contour plot. The centre plots depict the arrival momenta of the particles with the kinetic energy indicated by the contours. The right-hand plots show histograms of the potential energies of the particles}{figure.3}{}}
\newlabel{eq:EvolutionQTransformed}{{13}{7}{}{equation.3.13}{}}
\citation{Horowitz1991}
\citation{Neal2011}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Partial momentum update}{8}{subsection.3.4}}
\newlabel{sec:PartialMomentumUpdate}{{3.4}{8}{}{subsection.3.4}{}}
\abx@aux@page{25}{8}
\newlabel{eq:partialMomentumUpdate}{{15}{8}{}{equation.3.15}{}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces The HMC algorithm with partial momentum updates}}{8}{algorithm.2}}
\newlabel{alg:HMCWithPartial}{{2}{8}{}{algorithm.2}{}}
\newlabel{eq:StateAfterAcceptReject}{{16}{8}{}{equation.3.16}{}}
\citation{Salimans2014}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Flow chart illustrating the steps of the HMC algorithm with partial momentum updates.}}{9}{figure.4}}
\newlabel{fig:HMC_schematic}{{4}{9}{Flow chart illustrating the steps of the HMC algorithm with partial momentum updates}{figure.4}{}}
\abx@aux@page{26}{9}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}VI with HMC}{9}{section.4}}
\newlabel{sec:HMCVI}{{4}{9}{}{section.4}{}}
\abx@aux@page{27}{9}
\newlabel{eq:VIwithHMCPotEnergy}{{17}{9}{}{equation.4.17}{}}
\newlabel{sec:KinEnergyMayDependOnX}{{4}{9}{}{equation.4.17}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Deriving the variational lower bound}{9}{subsection.4.1}}
\newlabel{eq:HMCVIAuxLowerBound}{{19}{9}{}{equation.4.19}{}}
\citation{Salimans2014}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Transition densities without the acceptance step}{10}{subsection.4.2}}
\newlabel{sec:TransitionDensitiesNoAcceptance}{{4.2}{10}{}{subsection.4.2}{}}
\newlabel{eq:ForwardTransitionNoAcceptance}{{20}{10}{}{equation.4.20}{}}
\newlabel{eq:qUDefinition}{{21}{10}{}{equation.4.21}{}}
\newlabel{eq:ReverseTransitionNoAcceptance}{{22}{10}{}{equation.4.22}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Transition densities with the acceptance step}{10}{subsection.4.3}}
\abx@aux@page{28}{11}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Forward model}{11}{subsubsection.4.3.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Reverse model}{11}{subsubsection.4.3.2}}
\newlabel{sec:TransDensitiesWithAcceptReverse}{{4.3.2}{11}{}{subsubsection.4.3.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Learning the mass matrix}{12}{subsection.4.4}}
\newlabel{sec:MassMatrixChoice}{{4.4}{12}{}{subsection.4.4}{}}
\citation{Kingma2014}
\citation{Rezende2014}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Computational simplifications}{13}{subsection.4.5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Simplifications for HMCVI without partial momentum updates}{13}{subsubsection.4.5.1}}
\newlabel{sec:SimplificationWithoutPartialMomentumUpdate}{{4.5.1}{13}{}{subsubsection.4.5.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}Computing expectations explicitly}{13}{subsubsection.4.5.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Results}{13}{section.5}}
\newlabel{sec:Experiments}{{5}{13}{}{section.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Variational Auto-Encoders}{13}{subsection.5.1}}
\abx@aux@page{29}{13}
\abx@aux@page{30}{13}
\citation{LeCun1998}
\citation{Salakhutdinov2008}
\citation{Salimans2014}
\citation{Rezende2014}
\citation{Gregor2015}
\citation{Hinton2012}
\citation{Bergstra2010}
\citation{Bastien2012}
\citation{Kingma2015}
\citation{Bayer2015}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}The dataset and the effects of data binarization}{14}{subsection.5.2}}
\newlabel{sec:Dataset}{{5.2}{14}{}{subsection.5.2}{}}
\abx@aux@page{31}{14}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison of different binarization strategies on MNIST. The original (left) containing grey-scales was binarized using thresholding (middle) and stochastic binarization (right).}}{14}{figure.5}}
\newlabel{fig:MNISTBinarizationComparison}{{5}{14}{Comparison of different binarization strategies on MNIST. The original (left) containing grey-scales was binarized using thresholding (middle) and stochastic binarization (right)}{figure.5}{}}
\abx@aux@page{32}{14}
\abx@aux@page{33}{14}
\abx@aux@page{34}{14}
\abx@aux@page{35}{14}
\abx@aux@page{36}{14}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Model Specifications}{14}{subsection.5.3}}
\newlabel{sec:ModelSpecifications}{{5.3}{14}{}{subsection.5.3}{}}
\abx@aux@page{37}{14}
\abx@aux@page{38}{14}
\abx@aux@page{39}{14}
\abx@aux@page{40}{14}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Model Comparison}{15}{subsection.5.4}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of the obtained lower bound and marginal log-likelihood estimates for different HMCVI configurations with a 2-dimensional (top) and a 20-dimensional latent space (bottom). \#HMC and \#LF give the number of used HMC and leapfrog steps respectively. The fifth column indicates, whether partial momentum updates were permitted. The sixth column gives the strategy used for the covariance matrix $M$ of the canonical momentum distribution and the seventh column, whether the acceptance step was included and, if so, what approach was used (as described in section \ref  {sec:ModelSpecifications}). The last two columns report the lower bound $\mathcal  {L_\textrm  {aux}}$ and the estimated NLL on the test set.}}{16}{table.1}}
\newlabel{tab:Results}{{1}{16}{Comparison of the obtained lower bound and marginal log-likelihood estimates for different HMCVI configurations with a 2-dimensional (top) and a 20-dimensional latent space (bottom). \#HMC and \#LF give the number of used HMC and leapfrog steps respectively. The fifth column indicates, whether partial momentum updates were permitted. The sixth column gives the strategy used for the covariance matrix $M$ of the canonical momentum distribution and the seventh column, whether the acceptance step was included and, if so, what approach was used (as described in section \ref {sec:ModelSpecifications}). The last two columns report the lower bound $\mathcal {L_\textrm {aux}}$ and the estimated NLL on the test set}{table.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion and Future Work}{17}{section.6}}
\newlabel{sec:ConclAndFuture}{{6}{17}{}{section.6}{}}
\abx@aux@page{41}{17}
\abx@aux@page{42}{17}
\abx@aux@page{43}{17}
\abx@aux@page{44}{17}
\abx@aux@page{45}{17}
\abx@aux@page{46}{17}
\abx@aux@page{47}{17}
\abx@aux@page{48}{17}
\abx@aux@page{49}{18}
\abx@aux@page{50}{18}
\abx@aux@page{51}{18}
\abx@aux@page{52}{18}
\abx@aux@page{53}{18}
\abx@aux@page{54}{18}
\abx@aux@page{55}{18}
\abx@aux@page{56}{18}
\abx@aux@page{57}{18}
\abx@aux@page{58}{18}
\abx@aux@page{59}{18}
\abx@aux@page{60}{18}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{Appendices}{19}{section*.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{Appendix \numberline {A}Derivation of the reverse acceptance probability}{19}{Appendix.1.A}}
\newlabel{app:DerivationOfReverseAcceptanceProbability}{{A}{19}{}{Appendix.1.A}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{Appendix \numberline {B}Likelihood estimation by importance sampling}{19}{Appendix.1.B}}
\newlabel{app:NLLestimateImportSampling}{{B}{19}{}{Appendix.1.B}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Potential energy surface for the observed digit shown in the inset. The contours indicate the potential energy surface produced by a trained model with a 2-dimensional latent space. The plot also shows the mean images produced by the decoding model at evenly spaced points of the latent space.}}{19}{figure.6}}
\newlabel{fig:EnergySurfaceMNIST}{{6}{19}{Potential energy surface for the observed digit shown in the inset. The contours indicate the potential energy surface produced by a trained model with a 2-dimensional latent space. The plot also shows the mean images produced by the decoding model at evenly spaced points of the latent space}{figure.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{Appendix \numberline {C}Visualizations of latent space}{20}{Appendix.1.C}}
\newlabel{app:LatentVisualizations}{{C}{20}{}{Appendix.1.C}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Illustration of the two-dimensional latent space representation learnt by the model HMCVI 8 (see table\nobreakspace  {}\ref  {tab:Results}). To compensate for the Gaussian prior on the latent variables, linearly spaced coordinates in the unit square were transformed using the inverse Gaussian cdf. Therefore, the prior density in this view of latent space is uniform. For each coordinate the mean image produced by the decoder is shown. Additionally, the latent space representation of the training dataset as produced by the enhanced encoder is depicted (transformed by the Gaussian cdf), where each digit class is indicated by a different color.}}{20}{figure.7}}
\newlabel{fig:2d_latent_visualization}{{7}{20}{Illustration of the two-dimensional latent space representation learnt by the model HMCVI 8 (see table~\ref {tab:Results}). To compensate for the Gaussian prior on the latent variables, linearly spaced coordinates in the unit square were transformed using the inverse Gaussian cdf. Therefore, the prior density in this view of latent space is uniform. For each coordinate the mean image produced by the decoder is shown. Additionally, the latent space representation of the training dataset as produced by the enhanced encoder is depicted (transformed by the Gaussian cdf), where each digit class is indicated by a different color}{figure.7}{}}
